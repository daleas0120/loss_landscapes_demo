{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch_geometric.datasets import MoleculeNet\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "import copy\n",
    "import glob\n",
    "import json\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from torchinfo import summary\n",
    "from pymatgen.core.periodic_table import Element\n",
    "from collections import OrderedDict\n",
    "\n",
    "import loss_landscapes\n",
    "import loss_landscapes.metrics\n",
    "from loss_landscapes.model_interface.model_wrapper import ModelWrapper\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "from src import botcher_hessian as hess\n",
    "from src import botcher_utilities\n",
    "#from src import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU ...\n"
     ]
    }
   ],
   "source": [
    "if torch. cuda. is_available():\n",
    "    print(\"Using GPU ...\")\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>smiles</th>\n",
       "      <th>fingerprints</th>\n",
       "      <th>targets</th>\n",
       "      <th>clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>OCC3OC(OCC2OC(OC(C#N)c1ccccc1)C(O)C(O)C2O)C(O)...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>-0.770</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Cc1occc1C(=O)Nc2ccccc2</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>-3.300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CC(C)=CCCC(C)=CC(=O)</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>-2.060</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>c1ccc2c(c1)ccc3c2ccc4c5ccccc5ccc43</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>-7.870</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>c1ccsc1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>-1.330</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>1123</td>\n",
       "      <td>FC(F)(F)C(Cl)Br</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>-1.710</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>1124</td>\n",
       "      <td>CNC(=O)ON=C(SC)C(=O)N(C)C</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>1125</td>\n",
       "      <td>CCSCCSP(=S)(OC)OC</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>-3.091</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>1126</td>\n",
       "      <td>CCC(C)C</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>-3.180</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>1127</td>\n",
       "      <td>COP(=O)(OC)OC(=CCl)c1cc(Cl)c(Cl)cc1Cl</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>-4.522</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1128 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                             smiles  \\\n",
       "0              0  OCC3OC(OCC2OC(OC(C#N)c1ccccc1)C(O)C(O)C2O)C(O)...   \n",
       "1              1                             Cc1occc1C(=O)Nc2ccccc2   \n",
       "2              2                               CC(C)=CCCC(C)=CC(=O)   \n",
       "3              3                 c1ccc2c(c1)ccc3c2ccc4c5ccccc5ccc43   \n",
       "4              4                                            c1ccsc1   \n",
       "...          ...                                                ...   \n",
       "1123        1123                                   FC(F)(F)C(Cl)Br    \n",
       "1124        1124                          CNC(=O)ON=C(SC)C(=O)N(C)C   \n",
       "1125        1125                                  CCSCCSP(=S)(OC)OC   \n",
       "1126        1126                                            CCC(C)C   \n",
       "1127        1127              COP(=O)(OC)OC(=CCl)c1cc(Cl)c(Cl)cc1Cl   \n",
       "\n",
       "                                           fingerprints  targets  clusters  \n",
       "0     [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   -0.770         0  \n",
       "1     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   -3.300         0  \n",
       "2     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   -2.060         0  \n",
       "3     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   -7.870         0  \n",
       "4     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   -1.330         0  \n",
       "...                                                 ...      ...       ...  \n",
       "1123  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   -1.710         0  \n",
       "1124  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    0.106         0  \n",
       "1125  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   -3.091         0  \n",
       "1126  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   -3.180         0  \n",
       "1127  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   -4.522         0  \n",
       "\n",
       "[1128 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variable = \"esol_morgan\"\n",
    "\n",
    "clustered_data_file = \"/home/substrate/projects/molmim_embedding_prediction/data/clustered_%s.csv\"%variable\n",
    "best_model_file = \"/home/substrate/projects/molmim_embedding_prediction/data/models/best_model_%s.pth\"%variable\n",
    "\n",
    "df = pd.read_csv(clustered_data_file)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features and targets\n",
    "temp_ID_X = [ast.literal_eval(a) for a in df[df['clusters']==0]['fingerprints']]\n",
    "fingerprints = np.array([a for a in temp_ID_X])\n",
    "\n",
    "targets = np.asarray(df[df['clusters']==0]['targets'], dtype=np.float32)\n",
    "\n",
    "X_train, X_test_ID, y_train, y_test_ID  = train_test_split(fingerprints, targets, train_size=0.9, random_state=42)\n",
    "\n",
    "# Split the training set into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a PyTorch Dataset class\n",
    "class ESOLDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32).view(-1, 1)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Create DataLoader instances\n",
    "batch_size = 32\n",
    "train_dataset = ESOLDataset(X_train, y_train)\n",
    "validation_dataset = ESOLDataset(X_val, y_val)\n",
    "test_dataset = ESOLDataset(X_test_ID, y_test_ID)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define a PyTorch-based Gradient Boosting Model\n",
    "class BoostingRegressor(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, dropout_rate):\n",
    "        super(BoostingRegressor, self).__init__()\n",
    "        layers = []\n",
    "        layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.Dropout(dropout_rate))\n",
    "        for _ in range(num_layers - 2):\n",
    "            layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "        layers.append(nn.Linear(hidden_dim, 1))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "# Best parameters\n",
    "best_params = {'dropout_rate': np.float64(0.1624074561769746),\n",
    "                'hidden_dim': np.float64(93.9509479045509),\n",
    "                'lr': np.float64(0.0006750277604651748),\n",
    "                'num_layers': np.float64(4.598528437324806)}\n",
    "\n",
    "# Load model\n",
    "loaded_model = BoostingRegressor(input_dim=X_test_ID.shape[1], \n",
    "                                 hidden_dim=int(best_params['hidden_dim']), \n",
    "                                 num_layers=int(best_params['num_layers']), \n",
    "                                 dropout_rate=best_params['dropout_rate'])\n",
    "loaded_model.load_state_dict(torch.load(best_model_file))\n",
    "loaded_model.eval()\n",
    "print(\"Model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "BoostingRegressor                        --\n",
       "â”œâ”€Sequential: 1-1                        --\n",
       "â”‚    â””â”€Linear: 2-1                       190,557\n",
       "â”‚    â””â”€ReLU: 2-2                         --\n",
       "â”‚    â””â”€Dropout: 2-3                      --\n",
       "â”‚    â””â”€Linear: 2-4                       8,742\n",
       "â”‚    â””â”€ReLU: 2-5                         --\n",
       "â”‚    â””â”€Dropout: 2-6                      --\n",
       "â”‚    â””â”€Linear: 2-7                       8,742\n",
       "â”‚    â””â”€ReLU: 2-8                         --\n",
       "â”‚    â””â”€Dropout: 2-9                      --\n",
       "â”‚    â””â”€Linear: 2-10                      94\n",
       "=================================================================\n",
       "Total params: 208,135\n",
       "Trainable params: 208,135\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(loaded_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the Hessian Eigenvectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions are copy-pasted from Botcher implementation. I put them here so that I could debug more easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defaults from OG implementation\n",
    "loss_func = torch.nn.MSELoss()\n",
    "func = copy.deepcopy(loaded_model)\n",
    "og_params = [i[1] for i in func.named_parameters() if len(i[1].size()) > 1]\n",
    "og_layer_names = [i[0] for i in func.named_parameters() if len(i[1].size())>1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next cell calculates the eigenvectors, and can take considerable time (upwards of 40 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PyTorch Dataset class\n",
    "class XOnlyESOLDataset(Dataset):\n",
    "    def __init__(self, X):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx]\n",
    "\n",
    "# Create DataLoader instances\n",
    "batch_size = 32\n",
    "\n",
    "x_only_train_dataset = XOnlyESOLDataset(X_train)\n",
    "x_only_train_loader = DataLoader(x_only_train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207855\n"
     ]
    }
   ],
   "source": [
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "maxeig, mineig, maxeigvec, mineigvec, num_iter = hess.min_max_hessian_eigs(\n",
    "    func, X_train_tensor, y_train_tensor, loss_func, all_params=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124.58057 -0.9345152928753464\n"
     ]
    }
   ],
   "source": [
    "print(maxeig, mineig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting as two new models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n",
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "max_model_wts = hess.npvec_to_tensorlist(maxeigvec, og_params)\n",
    "min_model_wts = hess.npvec_to_tensorlist(mineigvec, og_params)\n",
    "\n",
    "model_eig_max = copy.deepcopy(func)\n",
    "model_eig_min = copy.deepcopy(func)\n",
    "\n",
    "# There will be some incompatible keys due to the batch norm values\n",
    "# the original batch norm values will be retained\n",
    "\n",
    "model_wt_dict = OrderedDict([i for i in loaded_model.named_parameters()])\n",
    "\n",
    "def force_wts_into_model(og_layer_names, new_model_wts, empty_model, old_model_state_dict):\n",
    "\n",
    "    new_model_wt_dict = copy.deepcopy(old_model_state_dict)\n",
    "\n",
    "    for layer, new_param in zip(og_layer_names, new_model_wts):\n",
    "        if new_param.shape == old_model_state_dict[layer].shape:\n",
    "            new_model_wt_dict[layer] = new_param\n",
    "        else:\n",
    "            print(layer+\" incompatible\")\n",
    "\n",
    "    err_layers = empty_model.load_state_dict(new_model_wt_dict, strict=False)\n",
    "    print(err_layers)\n",
    "\n",
    "    return empty_model\n",
    "\n",
    "model_eig_max = force_wts_into_model(og_layer_names, max_model_wts, model_eig_max,  model_wt_dict)\n",
    "model_eig_min = force_wts_into_model(og_layer_names, min_model_wts, model_eig_min,  model_wt_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_eig_max.state_dict(), 'data/models/model_eig_max.pt')\n",
    "torch.save(model_eig_min.state_dict(), 'data/models/model_eig_min.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "loss_landscapes_demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
