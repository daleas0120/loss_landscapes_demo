{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Hessian Loss Landscapes\n",
    "\n",
    "Ashley S. Dale\n",
    "\n",
    "Notebook loads a pretrained ALIGNN model, and calculates the loss landscape using Hessian directions\n",
    "\n",
    "\n",
    "- Relevant paper: [*Visualizing high-dimensional loss landscapes with Hessian directions* by Bottcher and Wheeler](https://iopscience.iop.org/article/10.1088/1742-5468/ad13fc/meta)\n",
    "\n",
    "---\n",
    "Notebook Outline:\n",
    "\n",
    "0. Select and load trained model and data\n",
    "\n",
    "0. Generate a set of predictions for the data\n",
    "\n",
    "0. Select a subset of well predicted instances to be \"In Distribution\" (ID) based on the z-score of the prediction error, where low z-score represents well predicted and therefore in-distribution\n",
    "\n",
    "0. Select a subset of poorly predicted instances to be \"Out of Distribution\" (OOD) based on the z-score of the prediction error, where a high z-score represents poorly predicted and therefore out-of-distribution\n",
    "\n",
    "0. Calculate the eigenvectors of the model's Hessian using the Hessian Vector Product\n",
    "\n",
    "0. Format two of the Hessians as two new models. These models will define the coordinate axes of the loss landscape\n",
    "\n",
    "0. Calculate the loss landscape using the original model as the origin, and the models generated from the eigenvectors of the Hessian as the two directions in which the original model is perturbed. Repeat this twice for the ID and OOD datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import glob\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "# import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from torchinfo import summary\n",
    "from pymatgen.core.periodic_table import Element\n",
    "from collections import OrderedDict\n",
    "\n",
    "import alignn\n",
    "from alignn.pretrained import *\n",
    "from jarvis.db.figshare import data\n",
    "from jarvis.db.figshare import data\n",
    "from jarvis.db.jsonutils import loadjson\n",
    "\n",
    "import loss_landscapes\n",
    "import loss_landscapes.metrics\n",
    "from loss_landscapes.model_interface.model_wrapper import ModelWrapper\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "from src.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch. cuda. is_available():\n",
    "    print(\"Using GPU ...\")\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_pretrained_models = list(get_all_models().keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> Select the `jv_formation_energy_peratom_alignn` model for the demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26053e0a540b49c48047b7614d192bca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Select Model', options=('jv_formation_energy_peratom_alignn', 'jv_optb88vdw_total_energy…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "style = {'description_width': 'initial'}\n",
    "\n",
    "config_selector = widgets.Dropdown(\n",
    "    options=list_of_pretrained_models,\n",
    "    value=list_of_pretrained_models[0],\n",
    "    description='Select Model',\n",
    "    style=style,\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "display(config_selector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected:  jv_formation_energy_peratom_alignn\n"
     ]
    }
   ],
   "source": [
    "# This is the model we will load\n",
    "model_name = config_selector.value\n",
    "print(\"Selected: \", model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using chk file jv_formation_energy_peratom_alignn/checkpoint_300.pt from  ['jv_formation_energy_peratom_alignn/checkpoint_300.pt']\n",
      "Path c:\\Users\\hanyu\\anaconda3_2\\envs\\losslandscapeEnv\\lib\\site-packages\\alignn\\jv_formation_energy_peratom_alignn.zip\n",
      "Config c:\\EH\\UT\\ML research\\loss_landscapes_demo\\jv_formation_energy_peratom_alignn\\config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hanyu\\anaconda3_2\\envs\\losslandscapeEnv\\lib\\site-packages\\alignn\\pretrained.py:292: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(filename, map_location=device)[\"model\"])\n"
     ]
    }
   ],
   "source": [
    "model = get_figshare_model(model_name)\n",
    "model.to(device)\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wt_dict = OrderedDict([i for i in model.named_parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "ALIGNN                                   --\n",
       "├─MLPLayer: 1-1                          --\n",
       "│    └─Sequential: 2-1                   --\n",
       "│    │    └─Linear: 3-1                  23,808\n",
       "│    │    └─BatchNorm1d: 3-2             512\n",
       "│    │    └─SiLU: 3-3                    --\n",
       "├─Sequential: 1-2                        --\n",
       "│    └─RBFExpansion: 2-2                 --\n",
       "│    └─MLPLayer: 2-3                     --\n",
       "│    │    └─Sequential: 3-4              5,312\n",
       "│    └─MLPLayer: 2-4                     --\n",
       "│    │    └─Sequential: 3-5              17,152\n",
       "├─Sequential: 1-3                        --\n",
       "│    └─RBFExpansion: 2-5                 --\n",
       "│    └─MLPLayer: 2-6                     --\n",
       "│    │    └─Sequential: 3-6              2,752\n",
       "│    └─MLPLayer: 2-7                     --\n",
       "│    │    └─Sequential: 3-7              17,152\n",
       "├─ModuleList: 1-4                        --\n",
       "│    └─ALIGNNConv: 2-8                   --\n",
       "│    │    └─EdgeGatedGraphConv: 3-8      329,984\n",
       "│    │    └─EdgeGatedGraphConv: 3-9      329,984\n",
       "│    └─ALIGNNConv: 2-9                   --\n",
       "│    │    └─EdgeGatedGraphConv: 3-10     329,984\n",
       "│    │    └─EdgeGatedGraphConv: 3-11     329,984\n",
       "│    └─ALIGNNConv: 2-10                  --\n",
       "│    │    └─EdgeGatedGraphConv: 3-12     329,984\n",
       "│    │    └─EdgeGatedGraphConv: 3-13     329,984\n",
       "│    └─ALIGNNConv: 2-11                  --\n",
       "│    │    └─EdgeGatedGraphConv: 3-14     329,984\n",
       "│    │    └─EdgeGatedGraphConv: 3-15     329,984\n",
       "├─ModuleList: 1-5                        --\n",
       "│    └─EdgeGatedGraphConv: 2-12          --\n",
       "│    │    └─Linear: 3-16                 65,792\n",
       "│    │    └─Linear: 3-17                 65,792\n",
       "│    │    └─Linear: 3-18                 65,792\n",
       "│    │    └─BatchNorm1d: 3-19            512\n",
       "│    │    └─Linear: 3-20                 65,792\n",
       "│    │    └─Linear: 3-21                 65,792\n",
       "│    │    └─BatchNorm1d: 3-22            512\n",
       "│    └─EdgeGatedGraphConv: 2-13          --\n",
       "│    │    └─Linear: 3-23                 65,792\n",
       "│    │    └─Linear: 3-24                 65,792\n",
       "│    │    └─Linear: 3-25                 65,792\n",
       "│    │    └─BatchNorm1d: 3-26            512\n",
       "│    │    └─Linear: 3-27                 65,792\n",
       "│    │    └─Linear: 3-28                 65,792\n",
       "│    │    └─BatchNorm1d: 3-29            512\n",
       "│    └─EdgeGatedGraphConv: 2-14          --\n",
       "│    │    └─Linear: 3-30                 65,792\n",
       "│    │    └─Linear: 3-31                 65,792\n",
       "│    │    └─Linear: 3-32                 65,792\n",
       "│    │    └─BatchNorm1d: 3-33            512\n",
       "│    │    └─Linear: 3-34                 65,792\n",
       "│    │    └─Linear: 3-35                 65,792\n",
       "│    │    └─BatchNorm1d: 3-36            512\n",
       "│    └─EdgeGatedGraphConv: 2-15          --\n",
       "│    │    └─Linear: 3-37                 65,792\n",
       "│    │    └─Linear: 3-38                 65,792\n",
       "│    │    └─Linear: 3-39                 65,792\n",
       "│    │    └─BatchNorm1d: 3-40            512\n",
       "│    │    └─Linear: 3-41                 65,792\n",
       "│    │    └─Linear: 3-42                 65,792\n",
       "│    │    └─BatchNorm1d: 3-43            512\n",
       "├─AvgPooling: 1-6                        --\n",
       "├─AvgPooling: 1-7                        --\n",
       "├─Linear: 1-8                            257\n",
       "=================================================================\n",
       "Total params: 4,026,753\n",
       "Trainable params: 4,026,753\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = 'optb88vdw_bandgap'\n",
    "target = 'formation_energy_peratom'\n",
    "n_samples = 200\n",
    "element_to_omit_from_training_data = 'Fe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining 3D dataset 76k ...\n",
      "Reference:https://www.nature.com/articles/s41524-020-00440-1\n",
      "Other versions:https://doi.org/10.6084/m9.figshare.6815699\n",
      "Loading the zipfile...\n",
      "Loading completed.\n",
      "num train samples: 186\n",
      "num test samples: 14\n"
     ]
    }
   ],
   "source": [
    "d = data(\"dft_3d\")\n",
    "d = d[:n_samples]\n",
    "dataset = DataFrame(copy.deepcopy(d))\n",
    "atoms_df = DataFrame(list(DataFrame(d)['atoms']))\n",
    "dataset = pd.concat([dataset, atoms_df], axis=1)\n",
    "train_idx, test_idx = get_split(dataset, 'elements', element_to_omit_from_training_data)\n",
    "print('num train samples: '+ str(len(train_idx)))\n",
    "print('num test samples: '+ str(len(test_idx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data range 2.71694 -3.53591\n",
      "Converting to graphs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 186/186 [00:01<00:00, 105.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df                                                  atoms     prop  jid\n",
      "0    {'lattice_mat': [[3.566933224304235, 0.0, -0.0... -0.42762    0\n",
      "1    {'lattice_mat': [[4.089078911208881, 0.0, 0.0]... -0.41596    1\n",
      "2    {'lattice_mat': [[-1.833590720595598, 1.833590...  0.04847    2\n",
      "3    {'lattice_mat': [[7.2963518353359165, 0.0, 0.0... -0.44140    3\n",
      "4    {'lattice_mat': [[1.6777483798834445, -2.90594... -0.71026    4\n",
      "..                                                 ...      ...  ...\n",
      "181  {'lattice_mat': [[3.5901111032581614, 0.0, 0.0... -0.39393  181\n",
      "182  {'lattice_mat': [[3.8231338005011324, 0.0, 0.0... -0.19644  182\n",
      "183  {'lattice_mat': [[5.343771579767017, 3.1726511... -2.63322  183\n",
      "184  {'lattice_mat': [[2.790143252692178, -2.680152... -1.55369  184\n",
      "185  {'lattice_mat': [[2.851156779425013, 0.0, -0.0... -2.49145  185\n",
      "\n",
      "[186 rows x 3 columns]\n",
      "warning: could not load CGCNN features for 103\n",
      "Setting it to max atomic number available here, 103\n",
      "warning: could not load CGCNN features for 101\n",
      "Setting it to max atomic number available here, 103\n",
      "warning: could not load CGCNN features for 102\n",
      "Setting it to max atomic number available here, 103\n",
      "building line graphs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 186/186 [00:00<00:00, 1715.45it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = [d[idx] for idx in train_idx.to_list()]\n",
    "train_dataloader = get_data_loader(train_data, target, workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting on Test and Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 186/186 [00:18<00:00,  9.90it/s]\n"
     ]
    }
   ],
   "source": [
    "model_train_predictions = []\n",
    "original_train_targets = []\n",
    "for s in tqdm(train_dataloader):\n",
    "    original_train_targets.append(s[2].detach().numpy()[0])\n",
    "    y_pred = model([s[0].to(device), s[1].to(device)])\n",
    "    y_pred = np.expand_dims(y_pred.cpu().detach().numpy(), axis=0)[0]\n",
    "    model_train_predictions.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data range 0.12011 -2.4143\n",
      "Converting to graphs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:00<00:00, 56.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df                                                 atoms     prop jid\n",
      "0   {'lattice_mat': [[3.790914410660539, -0.0, 0.0... -2.07159   0\n",
      "1   {'lattice_mat': [[4.927781968323723, -0.0, 0.0... -1.78124   1\n",
      "2   {'lattice_mat': [[4.839493559425439, 9.7116505... -1.66274   2\n",
      "3   {'lattice_mat': [[5.464512229851642, 0.0, -2.0... -0.93989   3\n",
      "4   {'lattice_mat': [[4.078736102710052, 0.3455178...  0.07844   4\n",
      "5   {'lattice_mat': [[2.80754625599962, 0.0, 0.0],... -2.41430   5\n",
      "6   {'lattice_mat': [[2.719421627743509, 4.2176232... -1.99266   6\n",
      "7   {'lattice_mat': [[4.857428829340624, 0.0, 0.0]... -2.22845   7\n",
      "8   {'lattice_mat': [[1.413929176152854, -2.448997... -2.23094   8\n",
      "9   {'lattice_mat': [[6.082481136762242, -0.039688...  0.12011   9\n",
      "10  {'lattice_mat': [[4.935947268149975, 0.0075616... -0.21301  10\n",
      "11  {'lattice_mat': [[4.293802725718504, 0.0, 0.0]... -1.39242  11\n",
      "12  {'lattice_mat': [[4.110215016104089, 0.0, 0.0]... -0.04638  12\n",
      "13  {'lattice_mat': [[6.93041047578813, 0.11598035... -1.97129  13\n",
      "building line graphs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:00<00:00, 2160.26it/s]\n",
      "100%|██████████| 14/14 [00:01<00:00,  9.79it/s]\n"
     ]
    }
   ],
   "source": [
    "test_data = [d[idx] for idx in test_idx.to_list()]\n",
    "test_dataloader = get_data_loader(test_data, target, workers=0)\n",
    "\n",
    "model_test_predictions = []\n",
    "original_test_targets = []\n",
    "for s in tqdm(test_dataloader):\n",
    "    original_test_targets.append(s[2].detach().numpy()[0])\n",
    "    y_pred = model([s[0].to(device), s[1].to(device)])\n",
    "    y_pred = np.expand_dims(y_pred.cpu().detach().numpy(), axis=0)[0]\n",
    "    model_test_predictions.append(y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subselect Train Data Samples: Most ID (Minimum Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_data)\n",
    "train_df['pred_val'] = model_train_predictions\n",
    "train_df['err'] = (train_df[target] - train_df['pred_val'])\n",
    "train_df['abs_err'] = np.abs(train_df[target] - train_df['pred_val'])\n",
    "train_df['z_score_err'] = (train_df['abs_err'] - np.mean(train_df['abs_err']))/np.std(train_df['abs_err'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jid</th>\n",
       "      <th>spg_number</th>\n",
       "      <th>spg_symbol</th>\n",
       "      <th>formula</th>\n",
       "      <th>formation_energy_peratom</th>\n",
       "      <th>func</th>\n",
       "      <th>optb88vdw_bandgap</th>\n",
       "      <th>atoms</th>\n",
       "      <th>slme</th>\n",
       "      <th>magmom_oszicar</th>\n",
       "      <th>...</th>\n",
       "      <th>bulk_modulus_kv</th>\n",
       "      <th>shear_modulus_gv</th>\n",
       "      <th>mbj_bandgap</th>\n",
       "      <th>hse_gap</th>\n",
       "      <th>reference</th>\n",
       "      <th>search</th>\n",
       "      <th>pred_val</th>\n",
       "      <th>err</th>\n",
       "      <th>abs_err</th>\n",
       "      <th>z_score_err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JVASP-90856</td>\n",
       "      <td>129</td>\n",
       "      <td>P4/nmm</td>\n",
       "      <td>TiCuSiAs</td>\n",
       "      <td>-0.42762</td>\n",
       "      <td>OptB88vdW</td>\n",
       "      <td>0.000</td>\n",
       "      <td>{'lattice_mat': [[3.566933224304235, 0.0, -0.0...</td>\n",
       "      <td>na</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>mp-1080455</td>\n",
       "      <td>-As-Cu-Si-Ti</td>\n",
       "      <td>-0.429359</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>-0.240511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JVASP-86097</td>\n",
       "      <td>221</td>\n",
       "      <td>Pm-3m</td>\n",
       "      <td>DyB6</td>\n",
       "      <td>-0.41596</td>\n",
       "      <td>OptB88vdW</td>\n",
       "      <td>0.000</td>\n",
       "      <td>{'lattice_mat': [[4.089078911208881, 0.0, 0.0]...</td>\n",
       "      <td>na</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>mp-568319</td>\n",
       "      <td>-B-Dy</td>\n",
       "      <td>-0.417615</td>\n",
       "      <td>0.001655</td>\n",
       "      <td>0.001655</td>\n",
       "      <td>-0.243626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JVASP-64906</td>\n",
       "      <td>119</td>\n",
       "      <td>I-4m2</td>\n",
       "      <td>Be2OsRu</td>\n",
       "      <td>0.04847</td>\n",
       "      <td>OptB88vdW</td>\n",
       "      <td>0.000</td>\n",
       "      <td>{'lattice_mat': [[-1.833590720595598, 1.833590...</td>\n",
       "      <td>na</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>auid-3eaf68dd483bf4f4</td>\n",
       "      <td>-Be-Os-Ru</td>\n",
       "      <td>0.046013</td>\n",
       "      <td>0.002457</td>\n",
       "      <td>0.002457</td>\n",
       "      <td>-0.213745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JVASP-98225</td>\n",
       "      <td>14</td>\n",
       "      <td>P2_1/c</td>\n",
       "      <td>KBi</td>\n",
       "      <td>-0.44140</td>\n",
       "      <td>OptB88vdW</td>\n",
       "      <td>0.472</td>\n",
       "      <td>{'lattice_mat': [[7.2963518353359165, 0.0, 0.0...</td>\n",
       "      <td>na</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>mp-31104</td>\n",
       "      <td>-Bi-K</td>\n",
       "      <td>-0.444024</td>\n",
       "      <td>0.002624</td>\n",
       "      <td>0.002624</td>\n",
       "      <td>-0.207543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JVASP-10</td>\n",
       "      <td>164</td>\n",
       "      <td>P-3m1</td>\n",
       "      <td>VSe2</td>\n",
       "      <td>-0.71026</td>\n",
       "      <td>OptB88vdW</td>\n",
       "      <td>0.000</td>\n",
       "      <td>{'lattice_mat': [[1.6777483798834445, -2.90594...</td>\n",
       "      <td>na</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>48.79</td>\n",
       "      <td>33.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>na</td>\n",
       "      <td>mp-694</td>\n",
       "      <td>-Se-V</td>\n",
       "      <td>-0.713197</td>\n",
       "      <td>0.002937</td>\n",
       "      <td>0.002937</td>\n",
       "      <td>-0.195889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           jid spg_number spg_symbol   formula  formation_energy_peratom  \\\n",
       "0  JVASP-90856        129     P4/nmm  TiCuSiAs                  -0.42762   \n",
       "1  JVASP-86097        221      Pm-3m      DyB6                  -0.41596   \n",
       "2  JVASP-64906        119      I-4m2   Be2OsRu                   0.04847   \n",
       "3  JVASP-98225         14     P2_1/c       KBi                  -0.44140   \n",
       "4     JVASP-10        164      P-3m1      VSe2                  -0.71026   \n",
       "\n",
       "        func  optb88vdw_bandgap  \\\n",
       "0  OptB88vdW              0.000   \n",
       "1  OptB88vdW              0.000   \n",
       "2  OptB88vdW              0.000   \n",
       "3  OptB88vdW              0.472   \n",
       "4  OptB88vdW              0.000   \n",
       "\n",
       "                                               atoms slme magmom_oszicar  ...  \\\n",
       "0  {'lattice_mat': [[3.566933224304235, 0.0, -0.0...   na            0.0  ...   \n",
       "1  {'lattice_mat': [[4.089078911208881, 0.0, 0.0]...   na            0.0  ...   \n",
       "2  {'lattice_mat': [[-1.833590720595598, 1.833590...   na            0.0  ...   \n",
       "3  {'lattice_mat': [[7.2963518353359165, 0.0, 0.0...   na            0.0  ...   \n",
       "4  {'lattice_mat': [[1.6777483798834445, -2.90594...   na            0.0  ...   \n",
       "\n",
       "  bulk_modulus_kv shear_modulus_gv mbj_bandgap  hse_gap  \\\n",
       "0              na               na          na       na   \n",
       "1              na               na          na       na   \n",
       "2              na               na          na       na   \n",
       "3              na               na          na       na   \n",
       "4           48.79            33.05         0.0       na   \n",
       "\n",
       "               reference        search  pred_val       err   abs_err  \\\n",
       "0             mp-1080455  -As-Cu-Si-Ti -0.429359  0.001739  0.001739   \n",
       "1              mp-568319         -B-Dy -0.417615  0.001655  0.001655   \n",
       "2  auid-3eaf68dd483bf4f4     -Be-Os-Ru  0.046013  0.002457  0.002457   \n",
       "3               mp-31104         -Bi-K -0.444024  0.002624  0.002624   \n",
       "4                 mp-694         -Se-V -0.713197  0.002937  0.002937   \n",
       "\n",
       "  z_score_err  \n",
       "0   -0.240511  \n",
       "1   -0.243626  \n",
       "2   -0.213745  \n",
       "3   -0.207543  \n",
       "4   -0.195889  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.hist(train_df['z_score_err'].values, bins=100)\n",
    "plt.title('Train Set Predictions (Omitting '+element_to_omit_from_training_data+')')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data range -0.39393 -3.08933\n",
      "Converting to graphs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 67.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df                                                atoms     prop jid\n",
      "0  {'lattice_mat': [[4.328319117003372, 1.032103e... -1.67055   0\n",
      "1  {'lattice_mat': [[4.9619896140897275, -8.59441... -3.08933   1\n",
      "2  {'lattice_mat': [[3.5901111032581614, 0.0, 0.0... -0.39393   2\n",
      "building line graphs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "train_subset_df = train_df.nsmallest(3, 'z_score_err')\n",
    "train_subset_df_idx = train_subset_df.index.values.tolist()\n",
    "train_subset_list = [train_data[i] for i in train_subset_df_idx]\n",
    "train_subset_dataloader = get_data_loader(train_subset_list, target, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jid</th>\n",
       "      <th>spg_number</th>\n",
       "      <th>spg_symbol</th>\n",
       "      <th>formula</th>\n",
       "      <th>formation_energy_peratom</th>\n",
       "      <th>func</th>\n",
       "      <th>optb88vdw_bandgap</th>\n",
       "      <th>atoms</th>\n",
       "      <th>slme</th>\n",
       "      <th>magmom_oszicar</th>\n",
       "      <th>...</th>\n",
       "      <th>bulk_modulus_kv</th>\n",
       "      <th>shear_modulus_gv</th>\n",
       "      <th>mbj_bandgap</th>\n",
       "      <th>hse_gap</th>\n",
       "      <th>reference</th>\n",
       "      <th>search</th>\n",
       "      <th>pred_val</th>\n",
       "      <th>err</th>\n",
       "      <th>abs_err</th>\n",
       "      <th>z_score_err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>JVASP-85271</td>\n",
       "      <td>164</td>\n",
       "      <td>P-3m1</td>\n",
       "      <td>La2PI2</td>\n",
       "      <td>-1.67055</td>\n",
       "      <td>OptB88vdW</td>\n",
       "      <td>0.000</td>\n",
       "      <td>{'lattice_mat': [[4.328319117003372, 1.032103e...</td>\n",
       "      <td>na</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>mp-571647</td>\n",
       "      <td>-I-La-P</td>\n",
       "      <td>-1.670515</td>\n",
       "      <td>-0.000035</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>-0.303967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>JVASP-13907</td>\n",
       "      <td>176</td>\n",
       "      <td>P6_3/m</td>\n",
       "      <td>Sr5P3ClO12</td>\n",
       "      <td>-3.08933</td>\n",
       "      <td>OptB88vdW</td>\n",
       "      <td>5.505</td>\n",
       "      <td>{'lattice_mat': [[4.9619896140897275, -8.59441...</td>\n",
       "      <td>na</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>mp-23121</td>\n",
       "      <td>-Cl-O-P-Sr</td>\n",
       "      <td>-3.089254</td>\n",
       "      <td>-0.000076</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>-0.302443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>JVASP-86845</td>\n",
       "      <td>6</td>\n",
       "      <td>Pm</td>\n",
       "      <td>NaLi5N2</td>\n",
       "      <td>-0.39393</td>\n",
       "      <td>OptB88vdW</td>\n",
       "      <td>0.683</td>\n",
       "      <td>{'lattice_mat': [[3.5901111032581614, 0.0, 0.0...</td>\n",
       "      <td>na</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>mp-569525</td>\n",
       "      <td>-Li-N-Na</td>\n",
       "      <td>-0.393834</td>\n",
       "      <td>-0.000096</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>-0.301687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             jid spg_number spg_symbol     formula  formation_energy_peratom  \\\n",
       "152  JVASP-85271        164      P-3m1      La2PI2                  -1.67055   \n",
       "164  JVASP-13907        176     P6_3/m  Sr5P3ClO12                  -3.08933   \n",
       "181  JVASP-86845          6         Pm     NaLi5N2                  -0.39393   \n",
       "\n",
       "          func  optb88vdw_bandgap  \\\n",
       "152  OptB88vdW              0.000   \n",
       "164  OptB88vdW              5.505   \n",
       "181  OptB88vdW              0.683   \n",
       "\n",
       "                                                 atoms slme magmom_oszicar  \\\n",
       "152  {'lattice_mat': [[4.328319117003372, 1.032103e...   na            0.0   \n",
       "164  {'lattice_mat': [[4.9619896140897275, -8.59441...   na            0.0   \n",
       "181  {'lattice_mat': [[3.5901111032581614, 0.0, 0.0...   na            0.0   \n",
       "\n",
       "     ... bulk_modulus_kv shear_modulus_gv mbj_bandgap  hse_gap  reference  \\\n",
       "152  ...              na               na          na       na  mp-571647   \n",
       "164  ...              na               na          na       na   mp-23121   \n",
       "181  ...              na               na          na       na  mp-569525   \n",
       "\n",
       "         search  pred_val       err   abs_err z_score_err  \n",
       "152     -I-La-P -1.670515 -0.000035  0.000035   -0.303967  \n",
       "164  -Cl-O-P-Sr -3.089254 -0.000076  0.000076   -0.302443  \n",
       "181    -Li-N-Na -0.393834 -0.000096  0.000096   -0.301687  \n",
       "\n",
       "[3 rows x 68 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_subset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_train_x = []\n",
    "subset_train_y = []\n",
    "\n",
    "for i in train_subset_dataloader:\n",
    "    subset_train_x.append((i[0], i[1]))\n",
    "    subset_train_y.append(i[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(test_data)\n",
    "test_df['pred_val'] = model_test_predictions\n",
    "test_df['err'] = (test_df[target] - test_df['pred_val'])\n",
    "test_df['abs_err'] = np.abs(test_df[target] - test_df['pred_val'])\n",
    "test_df['z_score_err'] = (test_df['abs_err'] - np.mean(train_df['abs_err']))/np.std(train_df['abs_err'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subselect Test Samples - Most OOD (Maximum Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data range 0.07844 -2.07159\n",
      "Converting to graphs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 82.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df                                                atoms     prop jid\n",
      "0  {'lattice_mat': [[3.790914410660539, -0.0, 0.0... -2.07159   0\n",
      "1  {'lattice_mat': [[4.110215016104089, 0.0, 0.0]... -0.04638   1\n",
      "2  {'lattice_mat': [[4.078736102710052, 0.3455178...  0.07844   2\n",
      "building line graphs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "test_subset_df = test_df.nlargest(3, 'z_score_err')\n",
    "test_subset_df_idx = test_subset_df.index.values.tolist()\n",
    "test_subset_list = [test_data[i] for i in test_subset_df_idx]\n",
    "test_subset_dataloader = get_data_loader(test_subset_list, target, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.hist(test_df['z_score_err'].values, bins=100,)\n",
    "plt.title('Test Set Predictions (Exclusively '+element_to_omit_from_training_data+')')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the Hessian Eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import botcher_hessian as hess\n",
    "from src import botcher_utilities as util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions are copy-pasted from Botcher implementation.  I put them here so that I could debug more easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def npvec_to_tensorlist(vec, params):\n",
    "    \"\"\" Convert a numpy vector to a list of tensor with the same dimensions as params\n",
    "\n",
    "        Args:\n",
    "            vec: a 1D numpy vector\n",
    "            params: a list of parameters from net\n",
    "\n",
    "        Returns:\n",
    "            rval: a list of tensors with the same shape as params\n",
    "    \"\"\"\n",
    "    loc = 0\n",
    "    rval = []\n",
    "    for p in params:\n",
    "        numel = p.data.numel()\n",
    "        rval.append(torch.from_numpy(vec[loc:loc+numel]).view(p.data.shape).float())\n",
    "        loc += numel\n",
    "    assert loc == vec.size, 'The vector has more elements than the net has parameters'\n",
    "    return rval\n",
    "\n",
    "\n",
    "def gradtensor_to_npvec(net, all_params=True):\n",
    "    \"\"\" Extract gradients from net, and return a concatenated numpy vector.\n",
    "\n",
    "        Args:\n",
    "            net: trained model\n",
    "            all_params: If all_params, then gradients w.r.t. BN parameters and bias\n",
    "            values are also included. Otherwise only gradients with dim > 1 are considered.\n",
    "\n",
    "        Returns:\n",
    "            a concatenated numpy vector containing all gradients\n",
    "    \"\"\"\n",
    "    filter = lambda p: all_params or len(p.data.size()) > 1\n",
    "    return np.concatenate([p.grad.data.cpu().numpy().ravel() for p in net.parameters() if filter(p)])\n",
    "\n",
    "\n",
    "def eval_hess_vec_prod(vec, params, net, loss_func, inputs_dataloader, outputs, use_cuda=False):\n",
    "    from torch.autograd import Variable\n",
    "    \"\"\"\n",
    "    Evaluate product of the Hessian of the loss function with a direction vector \"vec\".\n",
    "    The product result is saved in the grad of net.\n",
    "\n",
    "    Args:\n",
    "        vec: a list of tensor with the same dimensions as \"params\".\n",
    "        params: the parameter list of the net (ignoring biases and BN parameters).\n",
    "        net: model with trained parameters.\n",
    "        criterion: loss function.\n",
    "        inputs: nn inputs.\n",
    "        outputs: desired nn outputs.\n",
    "        use_cuda: use GPU.\n",
    "    \"\"\"\n",
    "\n",
    "    if use_cuda:\n",
    "        net.cuda()\n",
    "        vec = [v.cuda() for v in vec]\n",
    "\n",
    "    net.eval()\n",
    "    net.zero_grad() # clears grad for every parameter in the net\n",
    "    \n",
    "    ### OG IMPLEMENTATION\n",
    "    # pred_outputs = net(inputs.unsqueeze(-1)).flatten()\n",
    "    # pred_outputs = net(inputs_dataloader)\n",
    "    loss = torch.tensor(0.0).to(device)\n",
    "    for _, i in tqdm(enumerate(inputs_dataloader), total=len(inputs_dataloader)):\n",
    "        pred_outputs = net((i[0].to(device), i[1].to(device)))\n",
    "        # pred_outputs = np.expand_dims(pred_outputs.cpu().detach().numpy(), axis=0)[0]\n",
    "        outputs = i[2].to(device)\n",
    "        loss = torch.add(loss, loss_func(pred_outputs,outputs))\n",
    "    \n",
    "    loss = loss/len(inputs_dataloader)\n",
    "    grad_f = torch.autograd.grad(loss, inputs=params, create_graph=True, allow_unused=True)\n",
    "\n",
    "    # Compute inner product of gradient with the direction vector\n",
    "    prod = Variable(torch.zeros(1)).type(type(grad_f[0].data))\n",
    "\n",
    "    #for i in range(len(vec)):\n",
    "    tmp = []\n",
    "    for i in range(len(vec)):\n",
    "        if (grad_f[i] is not None) and (vec[i] is not None):\n",
    "            tmp.append((grad_f[i].to(device) * vec[i].to(device)).cpu().sum())\n",
    "    prod =+ sum(tmp)\n",
    "    # prod += sum([(grad_f[i] * vec[i]).cpu().sum() for i in range(len(vec))])\n",
    "\n",
    "    # Compute the Hessian-vector product, H*v\n",
    "    # prod.backward() computes dprod/dparams for every parameter in params and\n",
    "    # accumulate the gradients into the params.grad attributes\n",
    "    prod.backward()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_hessian_eigs(net, inputs, outputs, criterion, rank=0, use_cuda=False, verbose=False, all_params=True):\n",
    "    from scipy.sparse.linalg import LinearOperator, eigsh\n",
    "    import time\n",
    "    \"\"\"\n",
    "        Compute the largest and the smallest eigenvalues of the Hessian marix.\n",
    "\n",
    "        Args:\n",
    "            net: the trained model.\n",
    "            inputs: nn inputs.\n",
    "            outputs: desired nn outputs.\n",
    "            criterion: loss function.\n",
    "            rank: rank of the working node.\n",
    "            use_cuda: use GPU\n",
    "            verbose: print more information\n",
    "            all_params: use all nn parameters\n",
    "\n",
    "        Returns:\n",
    "            maxeig: max eigenvalue\n",
    "            mineig: min eigenvalue\n",
    "            hess_vec_prod.count: number of iterations for calculating max and min eigenvalues\n",
    "    \"\"\"\n",
    "    \n",
    "    if all_params:\n",
    "        params = [p for p in net.parameters()]\n",
    "    else:\n",
    "        params = [p for p in net.parameters() if len(p.size()) > 1]\n",
    "        \n",
    "    N = sum(p.numel() for p in params)\n",
    "\n",
    "    def hess_vec_prod(vec):\n",
    "        hess_vec_prod.count += 1  # simulates a static variable\n",
    "        vec = npvec_to_tensorlist(vec, params)\n",
    "        start_time = time.time()\n",
    "        eval_hess_vec_prod(vec, params, net, criterion, inputs, outputs, use_cuda)\n",
    "        prod_time = time.time() - start_time\n",
    "        if verbose and rank == 0: print(\"Iter: %d  time: %f\" % (hess_vec_prod.count, prod_time))\n",
    "        return gradtensor_to_npvec(net,all_params)\n",
    "        \n",
    "    hess_vec_prod.count = 0\n",
    "    if verbose and rank == 0: print(\"Rank %d: computing max eigenvalue\" % rank)\n",
    "\n",
    "    A = LinearOperator((N, N), matvec=hess_vec_prod)\n",
    "  \n",
    "    eigvals, eigvecs = eigsh(A, k=1, which='LM', tol=1e-2)\n",
    "    maxeig = eigvals[0]\n",
    "    maxeigvec = eigvecs\n",
    "    if verbose and rank == 0: print('max eigenvalue = %f' % maxeig)\n",
    "\n",
    "    # If the largest eigenvalue is positive, shift matrix so that any negative eigenvalue is now the largest\n",
    "    # We assume the smallest eigenvalue is zero or less, and so this shift is more than what we need\n",
    "    shift = maxeig*1.0\n",
    "    def shifted_hess_vec_prod(vec):\n",
    "        return hess_vec_prod(vec) - shift*vec\n",
    "\n",
    "    if verbose and rank == 0: print(\"Rank %d: Computing shifted eigenvalue\" % rank)\n",
    "\n",
    "    A = LinearOperator((N, N), matvec=shifted_hess_vec_prod)\n",
    "    eigvals, eigvecs = eigsh(A, k=1, which='LM', tol=1e-2)\n",
    "    eigvals = eigvals + shift\n",
    "    mineig = eigvals[0]\n",
    "    mineigvec = eigvecs\n",
    "    if verbose and rank == 0: print('min eigenvalue = ' + str(mineig))\n",
    "\n",
    "    if maxeig <= 0 and mineig > 0:\n",
    "        maxeig, mineig = mineig, maxeig\n",
    "        maxeig, mineig = mineigvec, maxeigvec\n",
    "\n",
    "    return maxeig, mineig, maxeigvec, mineigvec, hess_vec_prod.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defaults from OG implementation\n",
    "loss_func = torch.nn.MSELoss()\n",
    "func = copy.deepcopy(model)\n",
    "og_params = [i[1] for i in func.named_parameters() if len(i[1].size()) > 1]\n",
    "og_layer_names = [i[0] for i in func.named_parameters() if len(i[1].size())>1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next cell calculates the eigenvectors, and can take considerable time (upwards of 40 minutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here, we are computing the hessian eigenvectors using 3(or more) samples that 1. do not contain Fe, 2. is well predicted by the model (defined by existing model weights)\n",
    "\n",
    "then, we perturb the model such that the rate of loss increase would increase or we perturb the model such that the rate of loss increase would be constant\n",
    "\n",
    "we then test these perturbed model's performance on the same 3 samples that it had been predicting well to construct the loss land scape.\n",
    "\n",
    "- on the other hand, we will be picking samples that do not contain Fe and was not well predicted by the original model. they will not be involved in the hessian computation, so the perturbation has nothing to do with them. we will then test the perturbed model's performance on these samples\n",
    "\n",
    "hypothesis (need to be validated):\n",
    "\n",
    "perturbing in the direction of max eigenvector should increase/decress the loss by a lot (but that would be true for first derivative??? ask)\n",
    "\n",
    "perturbing in the direction of min eigenvector should not increase/decress the loss by a lot since it is the flattest direction\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- also, the choice of loss function is involved twice, 1. when we are choosing the samples; 2. when we are computing the hessian; 3. when we are visualizing the loss landscape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]c:\\Users\\hanyu\\anaconda3_2\\envs\\losslandscapeEnv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:608: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.75s/it]\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.71s/it]\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.70s/it]\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.69s/it]\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.83s/it]\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.93s/it]\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.83s/it]\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.76s/it]\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.77s/it]\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.77s/it]\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.77s/it]\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.82s/it]\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.81s/it]\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.78s/it]\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.77s/it]\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.78s/it]\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.83s/it]\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.81s/it]\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.80s/it]\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.83s/it]\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.82s/it]\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.80s/it]\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.80s/it]\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.80s/it]\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.80s/it]\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.79s/it]\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.83s/it]\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.79s/it]\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.80s/it]\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.77s/it]\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.76s/it]\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.79s/it]\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.80s/it]\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.77s/it]\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.80s/it]\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.80s/it]\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.79s/it]\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.79s/it]\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.82s/it]\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.79s/it]\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.77s/it]\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.80s/it]\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.75s/it]\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.76s/it]\n"
     ]
    }
   ],
   "source": [
    "maxeig, mineig, maxeigvec, mineigvec, num_iter = min_max_hessian_eigs(\n",
    "    func, train_subset_dataloader, subset_train_y, loss_func, all_params=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we found two directions of steepest and flattest curvature, the eigenvectors have unit length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.73587 -0.0003969979402569379\n"
     ]
    }
   ],
   "source": [
    "print(maxeig, mineig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Euclidean norm of the eigenvector is: 0.9999987483024597\n"
     ]
    }
   ],
   "source": [
    "norm = np.linalg.norm(maxeigvec)\n",
    "print(f\"The Euclidean norm of the eigenvector is: {norm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Euclidean norm of the weights is: 520.2879638671875\n"
     ]
    }
   ],
   "source": [
    "def unpack_tensors_to_1d(tensor_list):\n",
    "    \"\"\"Unpack a list of 2D tensors into a 1D NumPy array.\n",
    "\n",
    "    Args:\n",
    "        tensor_list: A list of 2D PyTorch tensors.\n",
    "\n",
    "    Returns:\n",
    "        A 1D NumPy array containing all elements from the tensors.\n",
    "    \"\"\"\n",
    "    # Flatten each tensor, detach from the computation graph, and convert to a NumPy array\n",
    "    flattened_arrays = [tensor.detach().flatten().numpy() for tensor in tensor_list]\n",
    "    \n",
    "    # Concatenate all flattened arrays into a single 1D array\n",
    "    result = np.concatenate(flattened_arrays)\n",
    "    \n",
    "    return result\n",
    "\n",
    "unpacked_array = unpack_tensors_to_1d(og_params)\n",
    "norm = np.linalg.norm(unpacked_array)\n",
    "print(f\"The Euclidean norm of the weights is: {norm}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatting as Two New Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_model_wts = hess.npvec_to_tensorlist(maxeigvec, og_params)\n",
    "min_model_wts = hess.npvec_to_tensorlist(mineigvec, og_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0489, -0.0350,  0.1071, -0.1211], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "og_params[0][0][:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.4091845e-04, -5.8035071e-06,  3.1937804e-04,  0.0000000e+00],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxeigvec[:4].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.4092e-04, -5.8035e-06,  3.1938e-04,  0.0000e+00])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_model_wts[0][0][:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_model_params = [i[1] for i in model_eig_max.named_parameters() if len(i[1].size()) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 1.4092e-04, -5.8035e-06,  3.1938e-04,  ...,  3.1938e-04,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [-4.3239e-06,  2.0644e-06, -1.8419e-06,  ..., -1.8419e-06,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [-3.7588e-06, -1.5764e-08, -2.1325e-05,  ..., -2.1325e-05,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        ...,\n",
       "        [ 7.0629e-06,  5.6602e-07,  2.1175e-05,  ...,  2.1175e-05,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [ 5.8127e-05, -6.4609e-08,  2.1141e-04,  ...,  2.1141e-04,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [ 2.4581e-06, -7.7974e-06, -2.2817e-05,  ..., -2.2817e-05,\n",
       "          0.0000e+00,  0.0000e+00]], requires_grad=True)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_model_params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eig_max = copy.deepcopy(func)\n",
    "model_eig_min = copy.deepcopy(func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "why are we using entries of our hessien eigenvector as parameters instead of adding the entries of eigenvector to our original weights? \n",
    "\n",
    "model_eig_max's weights are just eigenvector entries, it shouldnt have predictive power.\n",
    "\n",
    "we could be doing smth else when interpolating the model when constructing the losslandscape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_IncompatibleKeys(missing_keys=['atom_embedding.layer.1.running_mean', 'atom_embedding.layer.1.running_var', 'edge_embedding.0.centers', 'edge_embedding.1.layer.1.running_mean', 'edge_embedding.1.layer.1.running_var', 'edge_embedding.2.layer.1.running_mean', 'edge_embedding.2.layer.1.running_var', 'angle_embedding.0.centers', 'angle_embedding.1.layer.1.running_mean', 'angle_embedding.1.layer.1.running_var', 'angle_embedding.2.layer.1.running_mean', 'angle_embedding.2.layer.1.running_var', 'alignn_layers.0.node_update.bn_edges.running_mean', 'alignn_layers.0.node_update.bn_edges.running_var', 'alignn_layers.0.node_update.bn_nodes.running_mean', 'alignn_layers.0.node_update.bn_nodes.running_var', 'alignn_layers.0.edge_update.bn_edges.running_mean', 'alignn_layers.0.edge_update.bn_edges.running_var', 'alignn_layers.0.edge_update.bn_nodes.running_mean', 'alignn_layers.0.edge_update.bn_nodes.running_var', 'alignn_layers.1.node_update.bn_edges.running_mean', 'alignn_layers.1.node_update.bn_edges.running_var', 'alignn_layers.1.node_update.bn_nodes.running_mean', 'alignn_layers.1.node_update.bn_nodes.running_var', 'alignn_layers.1.edge_update.bn_edges.running_mean', 'alignn_layers.1.edge_update.bn_edges.running_var', 'alignn_layers.1.edge_update.bn_nodes.running_mean', 'alignn_layers.1.edge_update.bn_nodes.running_var', 'alignn_layers.2.node_update.bn_edges.running_mean', 'alignn_layers.2.node_update.bn_edges.running_var', 'alignn_layers.2.node_update.bn_nodes.running_mean', 'alignn_layers.2.node_update.bn_nodes.running_var', 'alignn_layers.2.edge_update.bn_edges.running_mean', 'alignn_layers.2.edge_update.bn_edges.running_var', 'alignn_layers.2.edge_update.bn_nodes.running_mean', 'alignn_layers.2.edge_update.bn_nodes.running_var', 'alignn_layers.3.node_update.bn_edges.running_mean', 'alignn_layers.3.node_update.bn_edges.running_var', 'alignn_layers.3.node_update.bn_nodes.running_mean', 'alignn_layers.3.node_update.bn_nodes.running_var', 'alignn_layers.3.edge_update.bn_edges.running_mean', 'alignn_layers.3.edge_update.bn_edges.running_var', 'alignn_layers.3.edge_update.bn_nodes.running_mean', 'alignn_layers.3.edge_update.bn_nodes.running_var', 'gcn_layers.0.bn_edges.running_mean', 'gcn_layers.0.bn_edges.running_var', 'gcn_layers.0.bn_nodes.running_mean', 'gcn_layers.0.bn_nodes.running_var', 'gcn_layers.1.bn_edges.running_mean', 'gcn_layers.1.bn_edges.running_var', 'gcn_layers.1.bn_nodes.running_mean', 'gcn_layers.1.bn_nodes.running_var', 'gcn_layers.2.bn_edges.running_mean', 'gcn_layers.2.bn_edges.running_var', 'gcn_layers.2.bn_nodes.running_mean', 'gcn_layers.2.bn_nodes.running_var', 'gcn_layers.3.bn_edges.running_mean', 'gcn_layers.3.bn_edges.running_var', 'gcn_layers.3.bn_nodes.running_mean', 'gcn_layers.3.bn_nodes.running_var'], unexpected_keys=[])\n",
      "_IncompatibleKeys(missing_keys=['atom_embedding.layer.1.running_mean', 'atom_embedding.layer.1.running_var', 'edge_embedding.0.centers', 'edge_embedding.1.layer.1.running_mean', 'edge_embedding.1.layer.1.running_var', 'edge_embedding.2.layer.1.running_mean', 'edge_embedding.2.layer.1.running_var', 'angle_embedding.0.centers', 'angle_embedding.1.layer.1.running_mean', 'angle_embedding.1.layer.1.running_var', 'angle_embedding.2.layer.1.running_mean', 'angle_embedding.2.layer.1.running_var', 'alignn_layers.0.node_update.bn_edges.running_mean', 'alignn_layers.0.node_update.bn_edges.running_var', 'alignn_layers.0.node_update.bn_nodes.running_mean', 'alignn_layers.0.node_update.bn_nodes.running_var', 'alignn_layers.0.edge_update.bn_edges.running_mean', 'alignn_layers.0.edge_update.bn_edges.running_var', 'alignn_layers.0.edge_update.bn_nodes.running_mean', 'alignn_layers.0.edge_update.bn_nodes.running_var', 'alignn_layers.1.node_update.bn_edges.running_mean', 'alignn_layers.1.node_update.bn_edges.running_var', 'alignn_layers.1.node_update.bn_nodes.running_mean', 'alignn_layers.1.node_update.bn_nodes.running_var', 'alignn_layers.1.edge_update.bn_edges.running_mean', 'alignn_layers.1.edge_update.bn_edges.running_var', 'alignn_layers.1.edge_update.bn_nodes.running_mean', 'alignn_layers.1.edge_update.bn_nodes.running_var', 'alignn_layers.2.node_update.bn_edges.running_mean', 'alignn_layers.2.node_update.bn_edges.running_var', 'alignn_layers.2.node_update.bn_nodes.running_mean', 'alignn_layers.2.node_update.bn_nodes.running_var', 'alignn_layers.2.edge_update.bn_edges.running_mean', 'alignn_layers.2.edge_update.bn_edges.running_var', 'alignn_layers.2.edge_update.bn_nodes.running_mean', 'alignn_layers.2.edge_update.bn_nodes.running_var', 'alignn_layers.3.node_update.bn_edges.running_mean', 'alignn_layers.3.node_update.bn_edges.running_var', 'alignn_layers.3.node_update.bn_nodes.running_mean', 'alignn_layers.3.node_update.bn_nodes.running_var', 'alignn_layers.3.edge_update.bn_edges.running_mean', 'alignn_layers.3.edge_update.bn_edges.running_var', 'alignn_layers.3.edge_update.bn_nodes.running_mean', 'alignn_layers.3.edge_update.bn_nodes.running_var', 'gcn_layers.0.bn_edges.running_mean', 'gcn_layers.0.bn_edges.running_var', 'gcn_layers.0.bn_nodes.running_mean', 'gcn_layers.0.bn_nodes.running_var', 'gcn_layers.1.bn_edges.running_mean', 'gcn_layers.1.bn_edges.running_var', 'gcn_layers.1.bn_nodes.running_mean', 'gcn_layers.1.bn_nodes.running_var', 'gcn_layers.2.bn_edges.running_mean', 'gcn_layers.2.bn_edges.running_var', 'gcn_layers.2.bn_nodes.running_mean', 'gcn_layers.2.bn_nodes.running_var', 'gcn_layers.3.bn_edges.running_mean', 'gcn_layers.3.bn_edges.running_var', 'gcn_layers.3.bn_nodes.running_mean', 'gcn_layers.3.bn_nodes.running_var'], unexpected_keys=[])\n"
     ]
    }
   ],
   "source": [
    "# There will be some incompatible keys due to the batch norm values\n",
    "# the original batch norm values will be retained\n",
    "model_eig_max = force_wts_into_model(og_layer_names, max_model_wts, model_eig_max,  model_wt_dict)\n",
    "model_eig_min = force_wts_into_model(og_layer_names, min_model_wts, model_eig_min,  model_wt_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_eig_max.state_dict(), 'model_eig_max.pt')\n",
    "torch.save(model_eig_min.state_dict(), 'model_eig_min.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
