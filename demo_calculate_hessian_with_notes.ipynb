{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Hessian Loss Landscapes\n",
    "\n",
    "Ashley S. Dale\n",
    "\n",
    "Notebook loads a pretrained ALIGNN model, and calculates the loss landscape using Hessian directions\n",
    "\n",
    "\n",
    "- Relevant paper: [*Visualizing high-dimensional loss landscapes with Hessian directions* by Bottcher and Wheeler](https://iopscience.iop.org/article/10.1088/1742-5468/ad13fc/meta)\n",
    "\n",
    "---\n",
    "Notebook Outline:\n",
    "\n",
    "0. Select and load trained model and data\n",
    "\n",
    "0. Generate a set of predictions for the data\n",
    "\n",
    "0. Select a subset of well predicted instances to be \"In Distribution\" (ID) based on the z-score of the prediction error, where low z-score represents well predicted and therefore in-distribution\n",
    "\n",
    "0. Select a subset of poorly predicted instances to be \"Out of Distribution\" (OOD) based on the z-score of the prediction error, where a high z-score represents poorly predicted and therefore out-of-distribution\n",
    "\n",
    "0. Calculate the eigenvectors of the model's Hessian using the Hessian Vector Product\n",
    "\n",
    "0. Format two of the Hessians as two new models. These models will define the coordinate axes of the loss landscape\n",
    "\n",
    "0. Calculate the loss landscape using the original model as the origin, and the models generated from the eigenvectors of the Hessian as the two directions in which the original model is perturbed. Repeat this twice for the ID and OOD datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import glob\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "# import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from torchinfo import summary\n",
    "from pymatgen.core.periodic_table import Element\n",
    "from collections import OrderedDict\n",
    "\n",
    "import alignn\n",
    "from alignn.pretrained import *\n",
    "from jarvis.db.figshare import data\n",
    "from jarvis.db.figshare import data\n",
    "from jarvis.db.jsonutils import loadjson\n",
    "\n",
    "import loss_landscapes\n",
    "import loss_landscapes.metrics\n",
    "from loss_landscapes.model_interface.model_wrapper import ModelWrapper\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "from src.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU ...\n"
     ]
    }
   ],
   "source": [
    "if torch. cuda. is_available():\n",
    "    print(\"Using GPU ...\")\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_pretrained_models = list(get_all_models().keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> Select the `jv_formation_energy_peratom_alignn` model for the demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bc301925b894a268837cf76939bec01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Select Model', options=('jv_formation_energy_peratom_alignn', 'jv_optb88vdw_total_energy…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "style = {'description_width': 'initial'}\n",
    "\n",
    "config_selector = widgets.Dropdown(\n",
    "    options=list_of_pretrained_models,\n",
    "    value=list_of_pretrained_models[0],\n",
    "    description='Select Model',\n",
    "    style=style,\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "display(config_selector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected:  jv_formation_energy_peratom_alignn\n"
     ]
    }
   ],
   "source": [
    "# This is the model we will load\n",
    "model_name = config_selector.value\n",
    "print(\"Selected: \", model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using chk file jv_formation_energy_peratom_alignn/checkpoint_300.pt from  ['jv_formation_energy_peratom_alignn/checkpoint_300.pt']\n",
      "Path c:\\Users\\EthanH24\\anaconda3\\envs\\losslandscapefeb8gpu4\\lib\\site-packages\\alignn\\jv_formation_energy_peratom_alignn.zip\n",
      "Config c:\\Users\\EthanH24\\Desktop\\ML research\\loss_landscapes_demo\\jv_formation_energy_peratom_alignn\\config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\EthanH24\\anaconda3\\envs\\losslandscapefeb8gpu4\\lib\\site-packages\\alignn\\pretrained.py:292: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(filename, map_location=device)[\"model\"])\n"
     ]
    }
   ],
   "source": [
    "model = get_figshare_model(model_name)\n",
    "model.to(device)\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wt_dict = OrderedDict([i for i in model.named_parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "ALIGNN                                   --\n",
       "├─MLPLayer: 1-1                          --\n",
       "│    └─Sequential: 2-1                   --\n",
       "│    │    └─Linear: 3-1                  23,808\n",
       "│    │    └─BatchNorm1d: 3-2             512\n",
       "│    │    └─SiLU: 3-3                    --\n",
       "├─Sequential: 1-2                        --\n",
       "│    └─RBFExpansion: 2-2                 --\n",
       "│    └─MLPLayer: 2-3                     --\n",
       "│    │    └─Sequential: 3-4              5,312\n",
       "│    └─MLPLayer: 2-4                     --\n",
       "│    │    └─Sequential: 3-5              17,152\n",
       "├─Sequential: 1-3                        --\n",
       "│    └─RBFExpansion: 2-5                 --\n",
       "│    └─MLPLayer: 2-6                     --\n",
       "│    │    └─Sequential: 3-6              2,752\n",
       "│    └─MLPLayer: 2-7                     --\n",
       "│    │    └─Sequential: 3-7              17,152\n",
       "├─ModuleList: 1-4                        --\n",
       "│    └─ALIGNNConv: 2-8                   --\n",
       "│    │    └─EdgeGatedGraphConv: 3-8      329,984\n",
       "│    │    └─EdgeGatedGraphConv: 3-9      329,984\n",
       "│    └─ALIGNNConv: 2-9                   --\n",
       "│    │    └─EdgeGatedGraphConv: 3-10     329,984\n",
       "│    │    └─EdgeGatedGraphConv: 3-11     329,984\n",
       "│    └─ALIGNNConv: 2-10                  --\n",
       "│    │    └─EdgeGatedGraphConv: 3-12     329,984\n",
       "│    │    └─EdgeGatedGraphConv: 3-13     329,984\n",
       "│    └─ALIGNNConv: 2-11                  --\n",
       "│    │    └─EdgeGatedGraphConv: 3-14     329,984\n",
       "│    │    └─EdgeGatedGraphConv: 3-15     329,984\n",
       "├─ModuleList: 1-5                        --\n",
       "│    └─EdgeGatedGraphConv: 2-12          --\n",
       "│    │    └─Linear: 3-16                 65,792\n",
       "│    │    └─Linear: 3-17                 65,792\n",
       "│    │    └─Linear: 3-18                 65,792\n",
       "│    │    └─BatchNorm1d: 3-19            512\n",
       "│    │    └─Linear: 3-20                 65,792\n",
       "│    │    └─Linear: 3-21                 65,792\n",
       "│    │    └─BatchNorm1d: 3-22            512\n",
       "│    └─EdgeGatedGraphConv: 2-13          --\n",
       "│    │    └─Linear: 3-23                 65,792\n",
       "│    │    └─Linear: 3-24                 65,792\n",
       "│    │    └─Linear: 3-25                 65,792\n",
       "│    │    └─BatchNorm1d: 3-26            512\n",
       "│    │    └─Linear: 3-27                 65,792\n",
       "│    │    └─Linear: 3-28                 65,792\n",
       "│    │    └─BatchNorm1d: 3-29            512\n",
       "│    └─EdgeGatedGraphConv: 2-14          --\n",
       "│    │    └─Linear: 3-30                 65,792\n",
       "│    │    └─Linear: 3-31                 65,792\n",
       "│    │    └─Linear: 3-32                 65,792\n",
       "│    │    └─BatchNorm1d: 3-33            512\n",
       "│    │    └─Linear: 3-34                 65,792\n",
       "│    │    └─Linear: 3-35                 65,792\n",
       "│    │    └─BatchNorm1d: 3-36            512\n",
       "│    └─EdgeGatedGraphConv: 2-15          --\n",
       "│    │    └─Linear: 3-37                 65,792\n",
       "│    │    └─Linear: 3-38                 65,792\n",
       "│    │    └─Linear: 3-39                 65,792\n",
       "│    │    └─BatchNorm1d: 3-40            512\n",
       "│    │    └─Linear: 3-41                 65,792\n",
       "│    │    └─Linear: 3-42                 65,792\n",
       "│    │    └─BatchNorm1d: 3-43            512\n",
       "├─AvgPooling: 1-6                        --\n",
       "├─AvgPooling: 1-7                        --\n",
       "├─Linear: 1-8                            257\n",
       "=================================================================\n",
       "Total params: 4,026,753\n",
       "Trainable params: 4,026,753\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = 'optb88vdw_bandgap'\n",
    "target = 'formation_energy_peratom'\n",
    "n_samples = 1000\n",
    "element_to_omit_from_training_data = 'Fe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining 3D dataset 76k ...\n",
      "Reference:https://www.nature.com/articles/s41524-020-00440-1\n",
      "Other versions:https://doi.org/10.6084/m9.figshare.6815699\n",
      "Loading the zipfile...\n",
      "Loading completed.\n",
      "num train samples: 927\n",
      "num test samples: 73\n"
     ]
    }
   ],
   "source": [
    "d = data(\"dft_3d\")\n",
    "d = d[:n_samples]\n",
    "dataset = DataFrame(copy.deepcopy(d))\n",
    "atoms_df = DataFrame(list(DataFrame(d)['atoms']))\n",
    "dataset = pd.concat([dataset, atoms_df], axis=1)\n",
    "train_idx, test_idx = get_split(dataset, 'elements', element_to_omit_from_training_data)\n",
    "print('num train samples: '+ str(len(train_idx)))\n",
    "print('num test samples: '+ str(len(test_idx)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting on Test and Train Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split all samples based having or not having Fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data range 5.28308 -4.0858\n",
      "Converting to graphs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 927/927 [00:06<00:00, 137.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df                                                  atoms     prop  jid\n",
      "0    {'lattice_mat': [[3.566933224304235, 0.0, -0.0... -0.42762    0\n",
      "1    {'lattice_mat': [[4.089078911208881, 0.0, 0.0]... -0.41596    1\n",
      "2    {'lattice_mat': [[-1.833590720595598, 1.833590...  0.04847    2\n",
      "3    {'lattice_mat': [[7.2963518353359165, 0.0, 0.0... -0.44140    3\n",
      "4    {'lattice_mat': [[1.6777483798834445, -2.90594... -0.71026    4\n",
      "..                                                 ...      ...  ...\n",
      "922  {'lattice_mat': [[0.0, 5.004301514431302, 5.00...  1.16087  922\n",
      "923  {'lattice_mat': [[4.496207811888019, 0.0, 0.0]... -1.90267  923\n",
      "924  {'lattice_mat': [[0.0, 3.852051785372815, 3.85...  0.41960  924\n",
      "925  {'lattice_mat': [[0.0, 4.9082744345175895, 4.9...  0.49906  925\n",
      "926  {'lattice_mat': [[0.0, 4.920264584239658, 4.92...  0.92931  926\n",
      "\n",
      "[927 rows x 3 columns]\n",
      "building line graphs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 927/927 [00:00<00:00, 2420.16it/s]\n",
      "100%|██████████| 927/927 [00:22<00:00, 41.03it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = [d[idx] for idx in train_idx.to_list()]\n",
    "train_dataloader = get_data_loader(train_data, target, workers=0)\n",
    "\n",
    "model_train_predictions = []\n",
    "original_train_targets = []\n",
    "for s in tqdm(train_dataloader):\n",
    "    original_train_targets.append(s[2].detach().numpy()[0])\n",
    "    y_pred = model([s[0].to(device), s[1].to(device)])\n",
    "    y_pred = np.expand_dims(y_pred.cpu().detach().numpy(), axis=0)[0]\n",
    "    model_train_predictions.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data range 1.56755 -2.65468\n",
      "Converting to graphs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [00:00<00:00, 107.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df                                                 atoms     prop jid\n",
      "0   {'lattice_mat': [[3.790914410660539, -0.0, 0.0... -2.07159   0\n",
      "1   {'lattice_mat': [[4.927781968323723, -0.0, 0.0... -1.78124   1\n",
      "2   {'lattice_mat': [[4.839493559425439, 9.7116505... -1.66274   2\n",
      "3   {'lattice_mat': [[5.464512229851642, 0.0, -2.0... -0.93989   3\n",
      "4   {'lattice_mat': [[4.078736102710052, 0.3455178...  0.07844   4\n",
      "..                                                ...      ...  ..\n",
      "68  {'lattice_mat': [[4.8166458682114435, -0.0, 0.... -1.28488  68\n",
      "69  {'lattice_mat': [[0.0, 4.589959301088131, 0.00... -1.70084  69\n",
      "70  {'lattice_mat': [[3.4709209595661688, -1.12804... -0.19524  70\n",
      "71  {'lattice_mat': [[-0.0, 3.24316049942265, 3.24...  0.14577  71\n",
      "72  {'lattice_mat': [[6.84938891863269, 1.15896e-1... -0.44277  72\n",
      "\n",
      "[73 rows x 3 columns]\n",
      "building line graphs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [00:00<00:00, 1921.02it/s]\n",
      "100%|██████████| 73/73 [00:01<00:00, 39.76it/s]\n"
     ]
    }
   ],
   "source": [
    "test_data = [d[idx] for idx in test_idx.to_list()]\n",
    "test_dataloader = get_data_loader(test_data, target, workers=0)\n",
    "\n",
    "model_test_predictions = []\n",
    "original_test_targets = []\n",
    "for s in tqdm(test_dataloader):\n",
    "    original_test_targets.append(s[2].detach().numpy()[0])\n",
    "    y_pred = model([s[0].to(device), s[1].to(device)])\n",
    "    y_pred = np.expand_dims(y_pred.cpu().detach().numpy(), axis=0)[0]\n",
    "    model_test_predictions.append(y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subselect Train Data Samples: Most ID (Minimum Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sample_in_loader = 50 #choose the number of samples involved in hessian computation and loss landscape visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute error for all training sample\n",
    "train_df = pd.DataFrame(train_data)\n",
    "train_df['pred_val'] = model_train_predictions\n",
    "train_df['err'] = (train_df[target] - train_df['pred_val'])\n",
    "train_df['abs_err'] = np.abs(train_df[target] - train_df['pred_val'])\n",
    "train_df['z_score_err'] = (train_df['abs_err'] - np.mean(train_df['abs_err']))/np.std(train_df['abs_err'])\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAHFCAYAAAAUpjivAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAQLBJREFUeJzt3XlclXXe//H3kU1AQBY9x5OoWJQamIlGYQkuYJZbzqhlmaY1mktRervUlNjtgNm4NNnmjFsu6d09aZuVuFGOOrdLVtoyVmqYImUEqAiG398f/TgzR8AFkYOXr+fjcT0ene/1Pdf1+V6H43n3va7rHJsxxggAAMCi6ni6AAAAgEuJsAMAACyNsAMAACyNsAMAACyNsAMAACyNsAMAACyNsAMAACyNsAMAACyNsAMAACyNsIPLhs1mO69l48aNF7WftLQ02Wy26in6/zt69KgmTZqkVq1aKTAwUCEhIWrRooUGDRqkzz777IK3d+jQIaWlpWnXrl3n1X/jxo1ux8jLy0t2u139+vXTl19+ecH7r4qkpCQlJSW5Hu/fv182m00LFy68oO188cUXSktL0/79+8utGzJkiJo1a3ZRdV5qr732mho0aKDCwkK39uPHj2vatGm68cYbVa9ePQUGBqpNmzZKT0/X8ePHq72Oio5Venq6Vq1aVa5vbT3mQ4YMqfTfgXffffeCttWxY0elpqZemkLheQa4TGzZssVtueOOO4y/v3+59vz8/IvaT3Z2ttmyZUs1VW1MYWGhueaaa4zD4TAzZswwa9euNe+8846ZMWOG6dChg1m0aNEFb3Pbtm1GklmwYMF59d+wYYORZNLT082WLVtMVlaWmTFjhgkJCTGhoaHm4MGDF1zDhUpMTDSJiYmuxydPnjRbtmwxubm5F7SdN954w0gyGzZsKLfum2++MTt37rzISi+d48ePm6uuuso899xzbu05OTkmJibG+Pv7mwkTJpg1a9aYNWvWmIkTJxp/f38TExNjcnJyqrWWio5VYGCgGTx4cLm+tfWYDx48uMJ/A7Zs2WLy8vIuaFsbN240Pj4+5quvvro0xcKjvD0btYDzd/PNN7s9btCggerUqVOu/UwnTpxQQEDAee+ncePGaty4cZVqrMgbb7yhb775RuvXr1enTp3c1j3++OM6ffp0te3rXKKjo13Hq2PHjqpfv76GDRumhQsX6sknn6zwORd6/M6Xn5/fOV+7C3X11VdX6/aq26JFi3T06FE9+OCDbu3333+/vvrqK23YsEG33nqrqz05OVl33nmnOnXqpMGDB+uDDz6otlqq61h5+pifz78B5yMxMVHXXXedZsyYoblz51ZDZahNOI0FS0lKSlJMTIw++ugjJSQkKCAgQEOHDpUkrVixQikpKWrUqJH8/f3VsmVLTZw4sdwpgopOYzVr1kw9evTQBx98oLZt28rf318tWrTQ/Pnzz1nT0aNHJUmNGjWqcH2dOu5vw71792rgwIFq2LCh/Pz81LJlS7344ouu9Rs3blT79u0lSQ888IBr2j4tLe2ctZyp7EPiwIEDkv499p07d+r3v/+9QkNDXR9mxhi99NJLatOmjfz9/RUaGqrf//73+u6779y2aYzR9OnT1bRpU9WtW1dt27bV+++/X27flZ3G+uqrr3TPPffIbrfLz89PTZo00f3336/i4mItXLhQ/fr1kyR16tTJNfaybVR0SuXkyZOaNGmSoqKi5Ovrq6uuukqjRo3SL7/84tbvfF/jEydOaNy4cYqKilLdunUVFhamdu3a6fXXXz/n8X755ZfVs2dP1a9f39W2fft2rVmzRsOGDXMLOmVuvfVWDR06VB9++KF27NjharfZbBo9erQWLFig6667Tv7+/mrXrp22bt0qY4yee+45RUVFqV69eurcubO++eYbt+2eeaxsNpuOHz+uRYsWuY5rUlJSlY55WW2LFy9Wy5YtFRAQoBtuuKHCU0tvvfWWWrduLT8/PzVv3lzPP/98tZ5KLikp0dSpU9WiRQv5+fmpQYMGeuCBB/Tjjz+W6zto0CAtW7as3ClGWICHZ5aAKhs8eLAJDAx0a0tMTDRhYWEmMjLSvPDCC2bDhg0mKyvLGGPMf//3f5tZs2aZ9957z2zcuNG88sorJioqynTq1MltG5MnTzZnvjWaNm1qGjdubFq1amVee+018+GHH5p+/foZSa7tV2bTpk1Gkmnfvr1ZuXKl+emnnyrtu2fPHhMSEmJiY2PNa6+9ZtasWWPGjh1r6tSpY9LS0owxxuTn55sFCxYYSeaPf/yja9o+Ozu70u2WncZ644033NrfeustI8k88cQTbmNv2rSpmTBhgsnMzDSrVq0yxhjz0EMPGR8fHzN27FjzwQcfmGXLlpkWLVoYu93udoqlbBvDhg0z77//vpk7d6656qqrjMPhcDuNtW/fvnKn4nbt2mXq1atnmjVrZl555RWzbt06s2TJEtO/f39TUFBgcnNzTXp6upFkXnzxRdfYy06FDR482DRt2tS1vdOnT5tu3boZb29v89RTT5k1a9aYP//5zyYwMNDceOON5uTJk66+5/saDx8+3AQEBJiZM2eaDRs2mHfffddMmzbNvPDCC5Uef2N+Oz0qybz00ktu7WXjef/99yt97urVq40kk5GR4Wore50SEhLMm2++aVauXGmuvfZaExYWZh577DHTu3dv8+6775qlS5cau91uWrdubU6fPu16/pnHasuWLcbf39/ccccdruO6Z8+eCz7mZbU1a9bM3HTTTeZ//ud/zOrVq01SUpLx9vY23377ravf+++/b+rUqWOSkpLMypUrzRtvvGHi4+NNs2bNyr0HK1L2b8CpU6fcll9//dUYY0xpaam5/fbbTWBgoJkyZYrJzMw0f/vb38xVV11lWrVqZU6cOOG2vX/+859Gknn77bfPuW9cXgg7uGxVFnYkmXXr1p31uadPnzanTp0yWVlZRpL59NNPXesqCzt169Y1Bw4ccLUVFRWZsLAwM3z48HPW+swzzxhfX18jyUgyUVFRZsSIEW77NcaYbt26mcaNG5e77mj06NGmbt265ueffzbGVP2anRUrVphTp06ZEydOmI8++shcc801xsvLy1VH2diffvppt+dv2bLFSDIzZsxwa8/Ozjb+/v5m/Pjxxhhj8vLyTN26dc1dd93l1u8f//iHkXTOsNO5c2dTv379s17Hc7brR8784P3ggw+MJDN9+nS3fitWrDCSzNy5c11t5/sax8TEmD59+lRaX2XK9rl161a39hEjRhhJZ71W5MsvvzSSzMMPP+xqk2QcDoc5duyYq23VqlVGkmnTpo1bsJk9e7aRZD777DNXW0UhpSrX7FQWdux2uykoKHC15eTkmDp16rgFtvbt25vIyEhTXFzsaissLDTh4eHnHXbK3lP/uXTo0MEYY8zrr79uJJm///3vbs8re/+cGTxLSkqMzWYzEyZMOOe+cXnhNBYsJzQ0VJ07dy7X/t1332ngwIFyOBzy8vKSj4+PEhMTJem87khq06aNmjRp4npct25dXXvtta5TQGfz1FNP6fvvv9f8+fM1fPhw1atXT6+88ori4uJcpz9OnjypdevW6a677lJAQIB+/fVX13LHHXfo5MmT2rp16/kehgoNGDBAPj4+CggIUMeOHVVaWqr//d//VevWrd36/e53v3N7/O6778pms+m+++5zq8vhcOiGG25w3QG3ZcsWnTx5Uvfee6/b8xMSEtS0adOz1nbixAllZWWpf//+atCgwUWNs8z69esl/Xaq5T/169dPgYGBWrdunVv7+bzGN910k95//31NnDhRGzduVFFR0XnVcujQIUlSw4YNL3gcxhhJKndqp1OnTgoMDHQ9btmypSSpe/fubn3L2s/nb7W6dOrUSUFBQa7HdrtdDRs2dNVw/Phxbd++XX369JGvr6+rX7169dSzZ8/z3o+/v7+2bdvmtsybN0/Sb3+39evXV8+ePd3+btu0aSOHw1Huzk0fHx/Vr19fP/zww0WMHLURFyjDciq6NubYsWO67bbbVLduXU2dOlXXXnutAgIClJ2drb59+57XB1Z4eHi5Nj8/v/P+sLPb7XrggQf0wAMPSJI++ugjde/eXY8++qjuueceHT16VL/++qteeOEFvfDCCxVu46effjqvfVXm2WefVefOneXl5aWIiAhFRkZW2O/MY3jkyBEZY2S32yvs37x5c0n/vj7J4XCU61NR23/Ky8tTaWlptV4cfvToUXl7e5cLTzabTQ6Hw1VvmfN5jf/yl7+ocePGWrFihZ599lnVrVtX3bp103PPPafo6OhKaynbRt26dd3ay8LVvn37dN1111X43LJbvs98vcLCwtwel4WGytpPnjxZaX3V7VzHMi8vr9K/qcr+zipSp04dtWvXrsJ1R44c0S+//OIWpv5TRe+nunXrnvd7GpcPwg4sp6ILG9evX69Dhw5p48aNrtkcSeUuUq1JHTt2VEpKilatWqXc3FyFhobKy8tLgwYN0qhRoyp8TlRU1EXts3nz5pV+MPynM49hRESEbDabPv74Y/n5+ZXrX9ZW9gGXk5NTrk9OTs5Zv48lLCxMXl5eOnjw4DnrO1/h4eH69ddf9eOPP7oFHmOMcnJyXBd6X4jAwEBNmTJFU6ZM0ZEjR1yzPD179tRXX31V6fMiIiIkST///LNbmExOTtYTTzyhVatW6fbbb6/wuWXffZOcnHzB9dZWoaGhstlsOnLkSLl1Ff39VEVERITCw8MrvYvtP2eeyuTl5bleK1gHp7FwRSj78D7zg/rVV1+95Ps+cuRIhbeXl5aWau/evQoICFD9+vUVEBCgTp066ZNPPlHr1q3Vrl27cktZmCgbR039H2iPHj1kjNEPP/xQYV2xsbGSfru7q27dulq6dKnb8zdv3nzOUyj+/v5KTEzUG2+8cdYZrAsZe5cuXSRJS5YscWv/+9//ruPHj7vWV5XdbteQIUN0zz336Ouvv9aJEycq7duiRQtJ0rfffuvW3q5dO6WkpGjevHn6xz/+Ue55mzZt0vz583X77bcrLi7uouo9l8pmKi/F31tgYKDatWunVatWqaSkxNV+7NixC/5CwMr06NFDR48eVWlpaYV/t2fOpB06dEgnT55Uq1atqmX/qD2Y2cEVISEhQaGhoRoxYoQmT54sHx8fLV26VJ9++ukl3/fixYv16quvauDAgWrfvr1CQkJ08OBB/e1vf9OePXv09NNPu6bZn3/+ed1666267bbb9PDDD6tZs2YqLCzUN998o3feecd1DcrVV18tf39/LV26VC1btlS9evXkdDrldDovyRg6dOigP/zhD3rggQe0fft2dezYUYGBgTp8+LA2bdqk2NhYPfzwwwoNDdW4ceM0depUPfjgg+rXr5+ys7OVlpZ2ztNYkjRz5kzdeuutio+P18SJE3XNNdfoyJEjevvtt/Xqq68qKChIMTExkqS5c+cqKChIdevWVVRUVIWnTZKTk9WtWzdNmDBBBQUF6tChgz777DNNnjxZN954owYNGnTBxyI+Pl49evRQ69atFRoaqi+//FKLFy/WLbfcctbvI4qPj5e/v7+2bt2qXr16ua177bXX1LVrV6WkpOiRRx5xhbD169fr+eefV4sWLS74m6arIjY2Vhs3btQ777yjRo0aKSgoSNddd90FHfML8cwzz+jOO+9Ut27d9Oijj6q0tFTPPfec6tWrp59//vmix3P33Xdr6dKluuOOO/Too4/qpptuko+Pjw4ePKgNGzaod+/euuuuu1z9y66JO/P7sGABHr08GrgIld2Ndf3111fYf/PmzeaWW24xAQEBpkGDBubBBx80O3fuLHdHUGV3Y915553ltnnmtwJX5IsvvjBjx4417dq1Mw0aNDDe3t4mNDTUJCYmmsWLF5frv2/fPjN06FBz1VVXGR8fH9OgQQOTkJBgpk6d6tbv9ddfNy1atDA+Pj5Gkpk8eXKlNVR26/mZysb+448/Vrh+/vz5Jj4+3gQGBhp/f39z9dVXm/vvv99s377d1ef06dMmIyPDREZGGl9fX9O6dWvzzjvvlDtWFd2NVXa8+vXrZ8LDw42vr69p0qSJGTJkiNtt4rNnzzZRUVHGy8vLbRsV3RlUVFRkJkyYYJo2bWp8fHxMo0aNzMMPP1zuG3bP9zWeOHGiadeunQkNDTV+fn6mefPm5rHHHjvrVwqUGTRokGnVqlWF644dO2bS09NNmzZtTEBAgAkICDCtW7c2U6dOdbvjqowkM2rUKLe2smN65jc0V/T6V3Ssdu3aZTp06GACAgLK3T13Ice8otqM+e0Yn3m318qVK01sbKzrtZ42bZp55JFHTGhoaIXH6T9V9G/AmU6dOmX+/Oc/mxtuuMHUrVvX1KtXz7Ro0cIMHz7c7N27163voEGDTGxs7Dn3i8uPzZj/f5k/AOCS2r59u9q3b6+tW7cqPj7e0+XUSqdOnVKbNm101VVXac2aNTW234KCAjmdTs2aNUsPPfRQje0XNYOwAwA1aMCAATp+/Hi1XZdyuRs2bJiSk5PVqFEj5eTk6JVXXlFWVpbWrFmjrl271lgdU6ZM0YoVK/TZZ5/J25srPKyGVxQAatCMGTM0b948FRYWVng30JWmsLBQ48aN048//igfHx+1bdtWq1evrtGgI0nBwcFauHAhQceimNkBAACWxq3nAADA0gg7AADA0gg7AADA0rgSS9Lp06d16NAhBQUFVfhTAwAAoPYxxqiwsFBOp1N16lQ+f0PY0W9fEV7ZDyICAIDaLTs7+6w/IkzY0b9/DC47O1vBwcEergYAAJyPgoICRUZGnvNrHAg7+vePRAYHBxN2AAC4zJzrEhQuUAYAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJbm0bDz66+/6o9//KOioqLk7++v5s2b65lnntHp06ddfYwxSktLk9PplL+/v5KSkrRnzx637RQXF2vMmDGKiIhQYGCgevXqpYMHD9b0cAAAQC3k0bDz7LPP6pVXXtGcOXP05Zdfavr06Xruuef0wgsvuPpMnz5dM2fO1Jw5c7Rt2zY5HA4lJyersLDQ1Sc1NVUrV67U8uXLtWnTJh07dkw9evRQaWmpJ4YFAABqEZsxxnhq5z169JDdbte8efNcbb/73e8UEBCgxYsXyxgjp9Op1NRUTZgwQdJvszh2u13PPvushg8frvz8fDVo0ECLFy/WgAEDJP37V8xXr16tbt26nbOOgoIChYSEKD8/n9/GAgDgMnG+n98endm59dZbtW7dOv3rX/+SJH366afatGmT7rjjDknSvn37lJOTo5SUFNdz/Pz8lJiYqM2bN0uSduzYoVOnTrn1cTqdiomJcfU5U3FxsQoKCtwWAABgTR791fMJEyYoPz9fLVq0kJeXl0pLS/WnP/1J99xzjyQpJydHkmS3292eZ7fbdeDAAVcfX19fhYaGlutT9vwzZWRkaMqUKdU9HAAAUAt5dGZnxYoVWrJkiZYtW6adO3dq0aJF+vOf/6xFixa59Tvzp9uNMef8Ofez9Zk0aZLy8/NdS3Z29sUNBAAA1Foendn5r//6L02cOFF33323JCk2NlYHDhxQRkaGBg8eLIfDIem32ZtGjRq5npebm+ua7XE4HCopKVFeXp7b7E5ubq4SEhIq3K+fn5/8/Pwu1bDcNJv4Xrm2/dPurJF9AwAAD8/snDhxQnXquJfg5eXluvU8KipKDodDmZmZrvUlJSXKyspyBZm4uDj5+Pi49Tl8+LB2795dadgBAABXDo/O7PTs2VN/+tOf1KRJE11//fX65JNPNHPmTA0dOlTSb6evUlNTlZ6erujoaEVHRys9PV0BAQEaOHCgJCkkJETDhg3T2LFjFR4errCwMI0bN06xsbHq2rWrJ4cHAABqAY+GnRdeeEFPPfWURo4cqdzcXDmdTg0fPlxPP/20q8/48eNVVFSkkSNHKi8vT/Hx8VqzZo2CgoJcfWbNmiVvb2/1799fRUVF6tKlixYuXCgvLy9PDAsAANQiHv2endriUn7PDtfsAABwaVwW37MDAABwqRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApXk07DRr1kw2m63cMmrUKEmSMUZpaWlyOp3y9/dXUlKS9uzZ47aN4uJijRkzRhEREQoMDFSvXr108OBBTwwHAADUQh4NO9u2bdPhw4ddS2ZmpiSpX79+kqTp06dr5syZmjNnjrZt2yaHw6Hk5GQVFha6tpGamqqVK1dq+fLl2rRpk44dO6YePXqotLTUI2MCAAC1i0fDToMGDeRwOFzLu+++q6uvvlqJiYkyxmj27Nl68skn1bdvX8XExGjRokU6ceKEli1bJknKz8/XvHnzNGPGDHXt2lU33nijlixZos8//1xr16715NAAAEAtUWuu2SkpKdGSJUs0dOhQ2Ww27du3Tzk5OUpJSXH18fPzU2JiojZv3ixJ2rFjh06dOuXWx+l0KiYmxtWnIsXFxSooKHBbAACANdWasLNq1Sr98ssvGjJkiCQpJydHkmS329362e1217qcnBz5+voqNDS00j4VycjIUEhIiGuJjIysxpEAAIDapNaEnXnz5ql79+5yOp1u7Tabze2xMaZc25nO1WfSpEnKz893LdnZ2VUvHAAA1Gq1IuwcOHBAa9eu1YMPPuhqczgcklRuhiY3N9c12+NwOFRSUqK8vLxK+1TEz89PwcHBbgsAALCmWhF2FixYoIYNG+rOO+90tUVFRcnhcLju0JJ+u64nKytLCQkJkqS4uDj5+Pi49Tl8+LB2797t6gMAAK5s3p4u4PTp01qwYIEGDx4sb+9/l2Oz2ZSamqr09HRFR0crOjpa6enpCggI0MCBAyVJISEhGjZsmMaOHavw8HCFhYVp3Lhxio2NVdeuXT01JAAAUIt4POysXbtW33//vYYOHVpu3fjx41VUVKSRI0cqLy9P8fHxWrNmjYKCglx9Zs2aJW9vb/Xv319FRUXq0qWLFi5cKC8vr5ocBgAAqKVsxhjj6SI8raCgQCEhIcrPz6/263eaTXyvXNv+aXdW0BMAAFyI8/38rhXX7AAAAFwqhB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBpHg87P/zwg+677z6Fh4crICBAbdq00Y4dO1zrjTFKS0uT0+mUv7+/kpKStGfPHrdtFBcXa8yYMYqIiFBgYKB69eqlgwcP1vRQAABALeTRsJOXl6cOHTrIx8dH77//vr744gvNmDFD9evXd/WZPn26Zs6cqTlz5mjbtm1yOBxKTk5WYWGhq09qaqpWrlyp5cuXa9OmTTp27Jh69Oih0tJSD4wKAADUJjZjjPHUzidOnKh//OMf+vjjjytcb4yR0+lUamqqJkyYIOm3WRy73a5nn31Ww4cPV35+vho0aKDFixdrwIABkqRDhw4pMjJSq1evVrdu3c5ZR0FBgUJCQpSfn6/g4ODqG6CkZhPfK9e2f9qd1boPAACuROf7+e3RmZ23335b7dq1U79+/dSwYUPdeOON+utf/+pav2/fPuXk5CglJcXV5ufnp8TERG3evFmStGPHDp06dcqtj9PpVExMjKvPmYqLi1VQUOC2AAAAa/Jo2Pnuu+/08ssvKzo6Wh9++KFGjBihRx55RK+99pokKScnR5Jkt9vdnme3213rcnJy5Ovrq9DQ0Er7nCkjI0MhISGuJTIysrqHBgAAagmPhp3Tp0+rbdu2Sk9P14033qjhw4froYce0ssvv+zWz2azuT02xpRrO9PZ+kyaNEn5+fmuJTs7++IGAgAAai2Php1GjRqpVatWbm0tW7bU999/L0lyOBySVG6GJjc31zXb43A4VFJSory8vEr7nMnPz0/BwcFuCwAAsCaPhp0OHTro66+/dmv717/+paZNm0qSoqKi5HA4lJmZ6VpfUlKirKwsJSQkSJLi4uLk4+Pj1ufw4cPavXu3qw8AALhyeXty54899pgSEhKUnp6u/v376//+7/80d+5czZ07V9Jvp69SU1OVnp6u6OhoRUdHKz09XQEBARo4cKAkKSQkRMOGDdPYsWMVHh6usLAwjRs3TrGxseratasnhwcAAGoBj4ad9u3ba+XKlZo0aZKeeeYZRUVFafbs2br33ntdfcaPH6+ioiKNHDlSeXl5io+P15o1axQUFOTqM2vWLHl7e6t///4qKipSly5dtHDhQnl5eXliWAAAoBbx6Pfs1BZ8zw4AAJefy+J7dgAAAC41wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0j4adtLQ02Ww2t8XhcLjWG2OUlpYmp9Mpf39/JSUlac+ePW7bKC4u1pgxYxQREaHAwED16tVLBw8erOmhAACAWsrjMzvXX3+9Dh8+7Fo+//xz17rp06dr5syZmjNnjrZt2yaHw6Hk5GQVFha6+qSmpmrlypVavny5Nm3apGPHjqlHjx4qLS31xHAAAEAt4+3xAry93WZzyhhjNHv2bD355JPq27evJGnRokWy2+1atmyZhg8frvz8fM2bN0+LFy9W165dJUlLlixRZGSk1q5dq27dutXoWAAAQO3j8ZmdvXv3yul0KioqSnfffbe+++47SdK+ffuUk5OjlJQUV18/Pz8lJiZq8+bNkqQdO3bo1KlTbn2cTqdiYmJcfQAAwJXNozM78fHxeu2113TttdfqyJEjmjp1qhISErRnzx7l5ORIkux2u9tz7Ha7Dhw4IEnKycmRr6+vQkNDy/Upe35FiouLVVxc7HpcUFBQXUMCAAC1jEfDTvfu3V3/HRsbq1tuuUVXX321Fi1apJtvvlmSZLPZ3J5jjCnXdqZz9cnIyNCUKVMuonIAAHC58PhprP8UGBio2NhY7d2713Udz5kzNLm5ua7ZHofDoZKSEuXl5VXapyKTJk1Sfn6+a8nOzq7mkQAAgNqiVoWd4uJiffnll2rUqJGioqLkcDiUmZnpWl9SUqKsrCwlJCRIkuLi4uTj4+PW5/Dhw9q9e7erT0X8/PwUHBzstgAAAGvy6GmscePGqWfPnmrSpIlyc3M1depUFRQUaPDgwbLZbEpNTVV6erqio6MVHR2t9PR0BQQEaODAgZKkkJAQDRs2TGPHjlV4eLjCwsI0btw4xcbGuu7OAgAAVzaPhp2DBw/qnnvu0U8//aQGDRro5ptv1tatW9W0aVNJ0vjx41VUVKSRI0cqLy9P8fHxWrNmjYKCglzbmDVrlry9vdW/f38VFRWpS5cuWrhwoby8vDw1LAAAUIvYjDHG00V4WkFBgUJCQpSfn1/tp7SaTXyvXNv+aXdW6z4AALgSne/nd626ZgcAAKC6EXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClVSnsNG/eXEePHi3X/ssvv6h58+YXXRQAAEB1qVLY2b9/v0pLS8u1FxcX64cffrjoogAAAKqL94V0fvvtt13//eGHHyokJMT1uLS0VOvWrVOzZs2qrTgAAICLdUFhp0+fPpIkm82mwYMHu63z8fFRs2bNNGPGjGorDgAA4GJdUNg5ffq0JCkqKkrbtm1TRETEJSkKAACgulxQ2Cmzb9++6q4DAADgkqhS2JGkdevWad26dcrNzXXN+JSZP3/+RRcGAABQHaoUdqZMmaJnnnlG7dq1U6NGjWSz2aq7LgAAgGpRpbDzyiuvaOHChRo0aFB11wMAAFCtqvQ9OyUlJUpISKjuWgAAAKpdlcLOgw8+qGXLllV3LQAAANWuSqexTp48qblz52rt2rVq3bq1fHx83NbPnDmzWooDAAC4WFUKO5999pnatGkjSdq9e7fbOi5WBgAAtUmVws6GDRuquw4AAIBLokrX7AAAAFwuqjSz06lTp7Oerlq/fn2VCwIAAKhOVQo7ZdfrlDl16pR27dql3bt3l/uBUAAAAE+qUtiZNWtWhe1paWk6duzYRRUEAABQnar1mp377ruP38UCAAC1SrWGnS1btqhu3brVuUkAAICLUqXTWH379nV7bIzR4cOHtX37dj311FPVUhgAAEB1qFLYCQkJcXtcp04dXXfddXrmmWeUkpJSLYUBAABUhyqdxlqwYIHbMm/ePE2bNu2igk5GRoZsNptSU1NdbcYYpaWlyel0yt/fX0lJSdqzZ4/b84qLizVmzBhFREQoMDBQvXr10sGDB6tcBwAAsJaLumZnx44dWrJkiZYuXapPPvmkytvZtm2b5s6dq9atW7u1T58+XTNnztScOXO0bds2ORwOJScnq7Cw0NUnNTVVK1eu1PLly7Vp0yYdO3ZMPXr0UGlpaZXrAQAA1lGlsJObm6vOnTurffv2euSRRzR69GjFxcWpS5cu+vHHHy9oW8eOHdO9996rv/71rwoNDXW1G2M0e/ZsPfnkk+rbt69iYmK0aNEinThxwvWL6/n5+Zo3b55mzJihrl276sYbb9SSJUv0+eefa+3atVUZGgAAsJgqhZ0xY8aooKBAe/bs0c8//6y8vDzt3r1bBQUFeuSRRy5oW6NGjdKdd96prl27urXv27dPOTk5bqfG/Pz8lJiYqM2bN0v6bWbp1KlTbn2cTqdiYmJcfSpSXFysgoICtwUAAFhTlS5Q/uCDD7R27Vq1bNnS1daqVSu9+OKLF3TdzvLly7Vz505t27at3LqcnBxJkt1ud2u32+06cOCAq4+vr6/bjFBZn7LnVyQjI0NTpkw57zoBAMDlq0ozO6dPn5aPj0+5dh8fH50+ffq8tpGdna1HH31US5YsOet385z5G1zGmLP+Ltf59Jk0aZLy8/NdS3Z29nnVDAAALj9VCjudO3fWo48+qkOHDrnafvjhBz322GPq0qXLeW1jx44dys3NVVxcnLy9veXt7a2srCz95S9/kbe3t2tG58wZmtzcXNc6h8OhkpIS5eXlVdqnIn5+fgoODnZbAACANVUp7MyZM0eFhYVq1qyZrr76al1zzTWKiopSYWGhXnjhhfPaRpcuXfT5559r165drqVdu3a69957tWvXLjVv3lwOh0OZmZmu55SUlCgrK0sJCQmSpLi4OPn4+Lj1OXz4sHbv3u3qAwAArmxVumYnMjJSO3fuVGZmpr766isZY9SqVatyFxmfTVBQkGJiYtzaAgMDFR4e7mpPTU1Venq6oqOjFR0drfT0dAUEBGjgwIGSfvtyw2HDhmns2LEKDw9XWFiYxo0bp9jY2AuqBQAAWNcFhZ3169dr9OjR2rp1q4KDg5WcnKzk5GRJv90Gfv311+uVV17RbbfdVi3FjR8/XkVFRRo5cqTy8vIUHx+vNWvWKCgoyNVn1qxZ8vb2Vv/+/VVUVKQuXbpo4cKF8vLyqpYaAADA5c1mjDHn27lXr17q1KmTHnvssQrX/+Uvf9GGDRu0cuXKaiuwJhQUFCgkJET5+fnVfv1Os4nvlWvbP+3Oat0HAABXovP9/L6ga3Y+/fRT3X777ZWuT0lJ0Y4dOy5kkwAAAJfUBYWdI0eOVHjLeRlvb+8L/gZlAACAS+mCws5VV12lzz//vNL1n332mRo1anTRRQEAAFSXCwo7d9xxh55++mmdPHmy3LqioiJNnjxZPXr0qLbiAAAALtYF3Y31xz/+UW+++aauvfZajR49Wtddd51sNpu+/PJLvfjiiyotLdWTTz55qWoFAAC4YBcUdux2uzZv3qyHH35YkyZNUtmNXDabTd26ddNLL7101m8uBgAAqGkX/KWCTZs21erVq5WXl6dvvvlGxhhFR0eX+zFOAACA2qBK36AsSaGhoWrfvn111gIAAFDtqvTbWAAAAJcLwg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0j4adl19+Wa1bt1ZwcLCCg4N1yy236P3333etN8YoLS1NTqdT/v7+SkpK0p49e9y2UVxcrDFjxigiIkKBgYHq1auXDh48WNNDAQAAtZRHw07jxo01bdo0bd++Xdu3b1fnzp3Vu3dvV6CZPn26Zs6cqTlz5mjbtm1yOBxKTk5WYWGhaxupqalauXKlli9frk2bNunYsWPq0aOHSktLPTUsAABQi9iMMcbTRfynsLAwPffccxo6dKicTqdSU1M1YcIESb/N4tjtdj377LMaPny48vPz1aBBAy1evFgDBgyQJB06dEiRkZFavXq1unXrdl77LCgoUEhIiPLz8xUcHFyt42k28b1ybfun3Vmt+wAA4Ep0vp/fteaandLSUi1fvlzHjx/XLbfcon379iknJ0cpKSmuPn5+fkpMTNTmzZslSTt27NCpU6fc+jidTsXExLj6VKS4uFgFBQVuCwAAsCaPh53PP/9c9erVk5+fn0aMGKGVK1eqVatWysnJkSTZ7Xa3/na73bUuJydHvr6+Cg0NrbRPRTIyMhQSEuJaIiMjq3lUAACgtvB42Lnuuuu0a9cubd26VQ8//LAGDx6sL774wrXeZrO59TfGlGs707n6TJo0Sfn5+a4lOzv74gYBAABqLY+HHV9fX11zzTVq166dMjIydMMNN+j555+Xw+GQpHIzNLm5ua7ZHofDoZKSEuXl5VXapyJ+fn6uO8DKFgAAYE0eDztnMsaouLhYUVFRcjgcyszMdK0rKSlRVlaWEhISJElxcXHy8fFx63P48GHt3r3b1QcAAFzZvD258yeeeELdu3dXZGSkCgsLtXz5cm3cuFEffPCBbDabUlNTlZ6erujoaEVHRys9PV0BAQEaOHCgJCkkJETDhg3T2LFjFR4errCwMI0bN06xsbHq2rWrJ4cGAABqCY+GnSNHjmjQoEE6fPiwQkJC1Lp1a33wwQdKTk6WJI0fP15FRUUaOXKk8vLyFB8frzVr1igoKMi1jVmzZsnb21v9+/dXUVGRunTpooULF8rLy8tTwwIAALVIrfueHU/ge3YAALj8XHbfswMAAHApEHYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAICleTTsZGRkqH379goKClLDhg3Vp08fff311259jDFKS0uT0+mUv7+/kpKStGfPHrc+xcXFGjNmjCIiIhQYGKhevXrp4MGDNTkUAABQS3k07GRlZWnUqFHaunWrMjMz9euvvyolJUXHjx939Zk+fbpmzpypOXPmaNu2bXI4HEpOTlZhYaGrT2pqqlauXKnly5dr06ZNOnbsmHr06KHS0lJPDAsAANQiNmOM8XQRZX788Uc1bNhQWVlZ6tixo4wxcjqdSk1N1YQJEyT9Notjt9v17LPPavjw4crPz1eDBg20ePFiDRgwQJJ06NAhRUZGavXq1erWrds591tQUKCQkBDl5+crODi4WsfUbOJ75dr2T7uzWvcBAMCV6Hw/v2vVNTv5+fmSpLCwMEnSvn37lJOTo5SUFFcfPz8/JSYmavPmzZKkHTt26NSpU259nE6nYmJiXH3OVFxcrIKCArcFAABYU60JO8YYPf7447r11lsVExMjScrJyZEk2e12t752u921LicnR76+vgoNDa20z5kyMjIUEhLiWiIjI6t7OAAAoJaoNWFn9OjR+uyzz/T666+XW2ez2dweG2PKtZ3pbH0mTZqk/Px815KdnV31wgEAQK1WK8LOmDFj9Pbbb2vDhg1q3Lixq93hcEhSuRma3Nxc12yPw+FQSUmJ8vLyKu1zJj8/PwUHB7stAADAmjwadowxGj16tN58802tX79eUVFRbuujoqLkcDiUmZnpaispKVFWVpYSEhIkSXFxcfLx8XHrc/jwYe3evdvVBwAAXLm8PbnzUaNGadmyZXrrrbcUFBTkmsEJCQmRv7+/bDabUlNTlZ6erujoaEVHRys9PV0BAQEaOHCgq++wYcM0duxYhYeHKywsTOPGjVNsbKy6du3qyeEBAIBawKNh5+WXX5YkJSUlubUvWLBAQ4YMkSSNHz9eRUVFGjlypPLy8hQfH681a9YoKCjI1X/WrFny9vZW//79VVRUpC5dumjhwoXy8vKqqaEAAIBaqlZ9z46n8D07AABcfi7L79kBAACoboQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaR4NOx999JF69uwpp9Mpm82mVatWua03xigtLU1Op1P+/v5KSkrSnj173PoUFxdrzJgxioiIUGBgoHr16qWDBw/W4CgAAEBt5tGwc/z4cd1www2aM2dOheunT5+umTNnas6cOdq2bZscDoeSk5NVWFjo6pOamqqVK1dq+fLl2rRpk44dO6YePXqotLS0poYBAABqMW9P7rx79+7q3r17heuMMZo9e7aefPJJ9e3bV5K0aNEi2e12LVu2TMOHD1d+fr7mzZunxYsXq2vXrpKkJUuWKDIyUmvXrlW3bt1qbCwAAKB2qrXX7Ozbt085OTlKSUlxtfn5+SkxMVGbN2+WJO3YsUOnTp1y6+N0OhUTE+PqAwAArmwendk5m5ycHEmS3W53a7fb7Tpw4ICrj6+vr0JDQ8v1KXt+RYqLi1VcXOx6XFBQUF1lAwCAWqbWzuyUsdlsbo+NMeXaznSuPhkZGQoJCXEtkZGR1VIrAACofWpt2HE4HJJUboYmNzfXNdvjcDhUUlKivLy8SvtUZNKkScrPz3ct2dnZ1Vw9AACoLWpt2ImKipLD4VBmZqarraSkRFlZWUpISJAkxcXFycfHx63P4cOHtXv3blefivj5+Sk4ONhtAQAA1uTRa3aOHTumb775xvV437592rVrl8LCwtSkSROlpqYqPT1d0dHRio6OVnp6ugICAjRw4EBJUkhIiIYNG6axY8cqPDxcYWFhGjdunGJjY113ZwEAgCubR8PO9u3b1alTJ9fjxx9/XJI0ePBgLVy4UOPHj1dRUZFGjhypvLw8xcfHa82aNQoKCnI9Z9asWfL29lb//v1VVFSkLl26aOHChfLy8qrx8QAAgNrHZowxni7C0woKChQSEqL8/PxqP6XVbOJ75dr2T7uzWvcBAMCV6Hw/v2vtNTsAAADVgbADAAAsjbADAAAsjbADAAAsjbADAAAsjbADAAAsjbADAAAsjbADAAAsjbADAAAsjbADAAAszaO/jXWlOvMnJPj5CAAALh1mdgAAgKURdgAAgKURdgAAgKURdgAAgKURdgAAgKURdgAAgKURdgAAgKURdgAAgKURdgAAgKURdgAAgKURdgAAgKURdgAAgKURdgAAgKURdgAAgKURdgAAgKURdgAAgKV5e7oASM0mvleubf+0Oz1QCQAA1sPMDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTLhJ2XXnpJUVFRqlu3ruLi4vTxxx97uqSL0mzie24LAACoGkvcer5ixQqlpqbqpZdeUocOHfTqq6+qe/fu+uKLL9SkSRNPl1ctuD0dAICqsRljjKeLuFjx8fFq27atXn75ZVdby5Yt1adPH2VkZJzz+QUFBQoJCVF+fr6Cg4OrtbaanpUhAAEArhTn+/l92c/slJSUaMeOHZo4caJbe0pKijZv3uyhqjznzHB1PuGHWSMAgJVd9mHnp59+Umlpqex2u1u73W5XTk5Ohc8pLi5WcXGx63F+fr6k3xJidTtdfKLat3khmjz2RpWed+axiJn8YZW2s3tKtwvezpnPqaqK9lVd264uZ9Z4PvVdynFVpR4AOFNN/VtS9ll1rpNUl33YKWOz2dweG2PKtZXJyMjQlClTyrVHRkZektouRyGzPbed6tp3TW+7OlS1vks1rtp+vABcHi71vyWFhYUKCQmpdP1lH3YiIiLk5eVVbhYnNze33GxPmUmTJunxxx93PT59+rR+/vlnhYeHVxqQqktBQYEiIyOVnZ1d7dcH4dw4/p7Ha+B5vAaexfGvPsYYFRYWyul0nrXfZR92fH19FRcXp8zMTN11112u9szMTPXu3bvC5/j5+cnPz8+trX79+peyzHKCg4P5I/cgjr/n8Rp4Hq+BZ3H8q8fZZnTKXPZhR5Ief/xxDRo0SO3atdMtt9yiuXPn6vvvv9eIESM8XRoAAPAwS4SdAQMG6OjRo3rmmWd0+PBhxcTEaPXq1WratKmnSwMAAB5mibAjSSNHjtTIkSM9XcY5+fn5afLkyeVOo6FmcPw9j9fA83gNPIvjX/Ms8aWCAAAAlbHMb2MBAABUhLADAAAsjbADAAAsjbADAAAsjbBTg1566SVFRUWpbt26iouL08cff+zpkq4YaWlpstlsbovD4fB0WZb20UcfqWfPnnI6nbLZbFq1apXbemOM0tLS5HQ65e/vr6SkJO3Zs8czxVrQuY7/kCFDyr0nbr75Zs8Ua0EZGRlq3769goKC1LBhQ/Xp00dff/21Wx/eAzWHsFNDVqxYodTUVD355JP65JNPdNttt6l79+76/vvvPV3aFeP666/X4cOHXcvnn3/u6ZIs7fjx47rhhhs0Z86cCtdPnz5dM2fO1Jw5c7Rt2zY5HA4lJyersLCwhiu1pnMdf0m6/fbb3d4Tq1evrsEKrS0rK0ujRo3S1q1blZmZqV9//VUpKSk6fvy4qw/vgRpkUCNuuukmM2LECLe2Fi1amIkTJ3qooivL5MmTzQ033ODpMq5YkszKlStdj0+fPm0cDoeZNm2aq+3kyZMmJCTEvPLKKx6o0NrOPP7GGDN48GDTu3dvj9RzJcrNzTWSTFZWljGG90BNY2anBpSUlGjHjh1KSUlxa09JSdHmzZs9VNWVZ+/evXI6nYqKitLdd9+t7777ztMlXbH27dunnJwct/eEn5+fEhMTeU/UoI0bN6phw4a69tpr9dBDDyk3N9fTJVlWfn6+JCksLEwS74GaRtipAT/99JNKS0vL/Qq73W4v92vtuDTi4+P12muv6cMPP9Rf//pX5eTkKCEhQUePHvV0aVeksr973hOe0717dy1dulTr16/XjBkztG3bNnXu3FnFxcWeLs1yjDF6/PHHdeuttyomJkYS74GaZpmfi7gc2Gw2t8fGmHJtuDS6d+/u+u/Y2Fjdcsstuvrqq7Vo0SI9/vjjHqzsysZ7wnMGDBjg+u+YmBi1a9dOTZs21Xvvvae+fft6sDLrGT16tD777DNt2rSp3DreAzWDmZ0aEBERIS8vr3JpPTc3t1yqR80IDAxUbGys9u7d6+lSrkhld8Lxnqg9GjVqpKZNm/KeqGZjxozR22+/rQ0bNqhx48audt4DNYuwUwN8fX0VFxenzMxMt/bMzEwlJCR4qKorW3Fxsb788ks1atTI06VckaKiouRwONzeEyUlJcrKyuI94SFHjx5VdnY274lqYozR6NGj9eabb2r9+vWKiopyW897oGZxGquGPP744xo0aJDatWunW265RXPnztX333+vESNGeLq0K8K4cePUs2dPNWnSRLm5uZo6daoKCgo0ePBgT5dmWceOHdM333zjerxv3z7t2rVLYWFhatKkiVJTU5Wenq7o6GhFR0crPT1dAQEBGjhwoAerto6zHf+wsDClpaXpd7/7nRo1aqT9+/friSeeUEREhO666y4PVm0do0aN0rJly/TWW28pKCjINYMTEhIif39/2Ww23gM1yaP3gl1hXnzxRdO0aVPj6+tr2rZt67oFEZfegAEDTKNGjYyPj49xOp2mb9++Zs+ePZ4uy9I2bNhgJJVbBg8ebIz57dbbyZMnG4fDYfz8/EzHjh3N559/7tmiLeRsx//EiRMmJSXFNGjQwPj4+JgmTZqYwYMHm++//97TZVtGRcdeklmwYIGrD++BmmMzxpiaj1gAAAA1g2t2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AFhWUlKSUlNTPV0GAA8j7AColXr27KmuXbtWuG7Lli2y2WzauXNnDVcF4HJE2AFQKw0bNkzr16/XgQMHyq2bP3++2rRpo7Zt23qgMgCXG8IOgFqpR48eatiwoRYuXOjWfuLECa1YsUJ9+vTRPffco8aNGysgIECxsbF6/fXXz7pNm82mVatWubXVr1/fbR8//PCDBgwYoNDQUIWHh6t3797av39/9QwKgEcQdgDUSt7e3rr//vu1cOFC/edP+L3xxhsqKSnRgw8+qLi4OL377rvavXu3/vCHP2jQoEH65z//WeV9njhxQp06dVK9evX00UcfadOmTapXr55uv/12lZSUVMewAHgAYQdArTV06FDt379fGzdudLXNnz9fffv21VVXXaVx48apTZs2at68ucaMGaNu3brpjTfeqPL+li9frjp16uhvf/ubYmNj1bJlSy1YsEDff/+9Ww0ALi/eni4AACrTokULJSQkaP78+erUqZO+/fZbffzxx1qzZo1KS0s1bdo0rVixQj/88IOKi4tVXFyswMDAKu9vx44d+uabbxQUFOTWfvLkSX377bcXOxwAHkLYAVCrDRs2TKNHj9aLL76oBQsWqGnTpurSpYuee+45zZo1S7Nnz1ZsbKwCAwOVmpp61tNNNpvN7ZSYJJ06dcr136dPn1ZcXJyWLl1a7rkNGjSovkEBqFGEHQC1Wv/+/fXoo49q2bJlWrRokR566CHZbDZ9/PHH6t27t+677z5JvwWVvXv3qmXLlpVuq0GDBjp8+LDr8d69e3XixAnX47Zt22rFihVq2LChgoODL92gANQortkBUKvVq1dPAwYM0BNPPKFDhw5pyJAhkqRrrrlGmZmZ2rx5s7788ksNHz5cOTk5Z91W586dNWfOHO3cuVPbt2/XiBEj5OPj41p/7733KiIiQr1799bHH3+sffv2KSsrS48++qgOHjx4KYcJ4BIi7ACo9YYNG6a8vDx17dpVTZo0kSQ99dRTatu2rbp166akpCQ5HA716dPnrNuZMWOGIiMj1bFjRw0cOFDjxo1TQECAa31AQIA++ugjNWnSRH379lXLli01dOhQFRUVMdMDXMZs5swT2AAAABbCzA4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALC0/wfHtsrtMpduhQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.hist(train_df['z_score_err'].values, bins=100)\n",
    "plt.title('Train Set Predictions (Omitting '+element_to_omit_from_training_data+')')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data range 1.31171 -3.24073\n",
      "Converting to graphs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 127.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df                                                 atoms     prop jid\n",
      "0   {'lattice_mat': [[5.614561710069512, -0.008098... -3.04140   0\n",
      "1   {'lattice_mat': [[4.428712142345245, 0.0938283... -1.15984   1\n",
      "2   {'lattice_mat': [[6.077481786895317, 0.0, 0.0]... -0.84152   2\n",
      "3   {'lattice_mat': [[7.542839764249747, 0.1718970... -0.44498   3\n",
      "4   {'lattice_mat': [[5.382597739169287, 0.0, -0.0... -2.65345   4\n",
      "5   {'lattice_mat': [[5.341766494740965, 4.8168425... -0.56058   5\n",
      "6   {'lattice_mat': [[3.413342172498346, 0.0, 0.0]... -1.42034   6\n",
      "7   {'lattice_mat': [[4.328319117003372, 1.032103e... -1.67055   7\n",
      "8   {'lattice_mat': [[5.995433144500313, 0.0005096... -0.39732   8\n",
      "9   {'lattice_mat': [[4.452327579413091, -0.007614... -1.46129   9\n",
      "10  {'lattice_mat': [[3.8371322574431592, 0.0, 0.0...  0.04698  10\n",
      "11  {'lattice_mat': [[3.4021647857751227, -3.63769... -3.08561  11\n",
      "12  {'lattice_mat': [[0.0, 4.897127193355007, 4.89...  0.29936  12\n",
      "13  {'lattice_mat': [[3.751609782599518, -0.0, -0....  0.28546  13\n",
      "14  {'lattice_mat': [[-5.2983347995314904, 0.00012... -1.28752  14\n",
      "15  {'lattice_mat': [[7.176688315920869, 0.0177224... -2.12074  15\n",
      "16  {'lattice_mat': [[2.7742217680271413, 4.091990... -0.95343  16\n",
      "17  {'lattice_mat': [[-0.0, 4.814357606223846, 4.8...  1.31171  17\n",
      "18  {'lattice_mat': [[4.9619896140897275, -8.59441... -3.08933  18\n",
      "19  {'lattice_mat': [[-0.0, 4.338166672957347, 4.3...  0.40293  19\n",
      "20  {'lattice_mat': [[4.038898205988307, -4.65024e... -0.64739  20\n",
      "21  {'lattice_mat': [[4.699408089813071, 0.0, 0.0]... -1.66196  21\n",
      "22  {'lattice_mat': [[6.072599402107012, -0.036450... -2.04247  22\n",
      "23  {'lattice_mat': [[5.558521476909106, 0.0, 0.0]... -2.72413  23\n",
      "24  {'lattice_mat': [[3.5901111032581614, 0.0, 0.0... -0.39393  24\n",
      "25  {'lattice_mat': [[4.2458238828472865, -9.24655... -0.51564  25\n",
      "26  {'lattice_mat': [[5.773610482753772, 0.0, 0.0]... -0.75957  26\n",
      "27  {'lattice_mat': [[7.641597528586177, 0.0, -4.9... -2.16254  27\n",
      "28  {'lattice_mat': [[-2.957792787404249, -7.86090... -1.21096  28\n",
      "29  {'lattice_mat': [[7.139992754882152, 0.0627425... -2.51457  29\n",
      "30  {'lattice_mat': [[-0.0, 4.896339150327006, 4.8...  1.24720  30\n",
      "31  {'lattice_mat': [[4.189561544891597, -0.018769... -0.49153  31\n",
      "32  {'lattice_mat': [[0.0, 4.859331879422273, 4.85...  0.61219  32\n",
      "33  {'lattice_mat': [[0.0, 4.900914308261845, 4.90...  1.15842  33\n",
      "34  {'lattice_mat': [[0.0, 0.0, -3.878379352212096... -0.52033  34\n",
      "35  {'lattice_mat': [[-0.0, 4.089020974510768, 4.0...  1.19689  35\n",
      "36  {'lattice_mat': [[0.0, 4.939183293766963, 4.93...  0.12510  36\n",
      "37  {'lattice_mat': [[7.394501076210965, -1.65096e... -3.24073  37\n",
      "38  {'lattice_mat': [[4.755191613611486, 0.0409644... -2.05465  38\n",
      "39  {'lattice_mat': [[8.058036444905524, -0.0, -0.... -1.60264  39\n",
      "40  {'lattice_mat': [[3.9020001613090693, -0.00529... -0.38818  40\n",
      "41  {'lattice_mat': [[9.490795691456137, 0.0227322... -0.26827  41\n",
      "42  {'lattice_mat': [[5.691918346156999, -8.976846... -2.66891  42\n",
      "43  {'lattice_mat': [[4.74015426190946, 0.0, -0.05... -3.12111  43\n",
      "44  {'lattice_mat': [[5.454590982353622, 0.0, 0.0]... -2.55245  44\n",
      "45  {'lattice_mat': [[5.532928684449406, -1.573926... -0.07592  45\n",
      "46  {'lattice_mat': [[1.3e-15, 5.835276375487073, ... -1.45115  46\n",
      "47  {'lattice_mat': [[2.1426299016085606, -3.71114... -0.58149  47\n",
      "48  {'lattice_mat': [[-0.0, 4.995305749731112, 4.9...  1.05384  48\n",
      "49  {'lattice_mat': [[0.0, 5.149359721977099, 5.14...  0.41076  49\n",
      "building line graphs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 2083.24it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jid</th>\n",
       "      <th>spg_number</th>\n",
       "      <th>spg_symbol</th>\n",
       "      <th>formula</th>\n",
       "      <th>formation_energy_peratom</th>\n",
       "      <th>func</th>\n",
       "      <th>optb88vdw_bandgap</th>\n",
       "      <th>atoms</th>\n",
       "      <th>slme</th>\n",
       "      <th>magmom_oszicar</th>\n",
       "      <th>...</th>\n",
       "      <th>bulk_modulus_kv</th>\n",
       "      <th>shear_modulus_gv</th>\n",
       "      <th>mbj_bandgap</th>\n",
       "      <th>hse_gap</th>\n",
       "      <th>reference</th>\n",
       "      <th>search</th>\n",
       "      <th>pred_val</th>\n",
       "      <th>err</th>\n",
       "      <th>abs_err</th>\n",
       "      <th>z_score_err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>JVASP-98452</td>\n",
       "      <td>2</td>\n",
       "      <td>P-1</td>\n",
       "      <td>K2Ca3Si3O10</td>\n",
       "      <td>-3.04140</td>\n",
       "      <td>OptB88vdW</td>\n",
       "      <td>4.228</td>\n",
       "      <td>{'lattice_mat': [[5.614561710069512, -0.008098...</td>\n",
       "      <td>na</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>mp-1019747</td>\n",
       "      <td>-Ca-K-O-Si</td>\n",
       "      <td>-3.041397</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.227288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>JVASP-86159</td>\n",
       "      <td>8</td>\n",
       "      <td>Cm</td>\n",
       "      <td>Ca3SiBr2</td>\n",
       "      <td>-1.15984</td>\n",
       "      <td>OptB88vdW</td>\n",
       "      <td>0.000</td>\n",
       "      <td>{'lattice_mat': [[4.428712142345245, 0.0938283...</td>\n",
       "      <td>na</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>0.0</td>\n",
       "      <td>na</td>\n",
       "      <td>mp-568791</td>\n",
       "      <td>-Br-Ca-Si</td>\n",
       "      <td>-1.159848</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>-0.227182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>JVASP-85713</td>\n",
       "      <td>26</td>\n",
       "      <td>Pmc2_1</td>\n",
       "      <td>LiHS</td>\n",
       "      <td>-0.84152</td>\n",
       "      <td>OptB88vdW</td>\n",
       "      <td>3.501</td>\n",
       "      <td>{'lattice_mat': [[6.077481786895317, 0.0, 0.0]...</td>\n",
       "      <td>na</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23.69</td>\n",
       "      <td>5.55</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>mp-644419</td>\n",
       "      <td>-H-Li-S</td>\n",
       "      <td>-0.841544</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>-0.226805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>JVASP-5503</td>\n",
       "      <td>2</td>\n",
       "      <td>P-1</td>\n",
       "      <td>TeAuCl7</td>\n",
       "      <td>-0.44498</td>\n",
       "      <td>OptB88vdW</td>\n",
       "      <td>1.466</td>\n",
       "      <td>{'lattice_mat': [[7.542839764249747, 0.1718970...</td>\n",
       "      <td>20.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>2.126</td>\n",
       "      <td>na</td>\n",
       "      <td>mp-28330</td>\n",
       "      <td>-Au-Cl-Te</td>\n",
       "      <td>-0.445009</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>-0.226706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>JVASP-97814</td>\n",
       "      <td>62</td>\n",
       "      <td>Pnma</td>\n",
       "      <td>Sn2BF7</td>\n",
       "      <td>-2.65345</td>\n",
       "      <td>OptB88vdW</td>\n",
       "      <td>4.390</td>\n",
       "      <td>{'lattice_mat': [[5.382597739169287, 0.0, -0.0...</td>\n",
       "      <td>na</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>mp-27430</td>\n",
       "      <td>-B-F-Sn</td>\n",
       "      <td>-2.653481</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>-0.226656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             jid spg_number spg_symbol      formula  formation_energy_peratom  \\\n",
       "716  JVASP-98452          2        P-1  K2Ca3Si3O10                  -3.04140   \n",
       "906  JVASP-86159          8         Cm     Ca3SiBr2                  -1.15984   \n",
       "219  JVASP-85713         26     Pmc2_1         LiHS                  -0.84152   \n",
       "475   JVASP-5503          2        P-1      TeAuCl7                  -0.44498   \n",
       "696  JVASP-97814         62       Pnma       Sn2BF7                  -2.65345   \n",
       "\n",
       "          func  optb88vdw_bandgap  \\\n",
       "716  OptB88vdW              4.228   \n",
       "906  OptB88vdW              0.000   \n",
       "219  OptB88vdW              3.501   \n",
       "475  OptB88vdW              1.466   \n",
       "696  OptB88vdW              4.390   \n",
       "\n",
       "                                                 atoms   slme magmom_oszicar  \\\n",
       "716  {'lattice_mat': [[5.614561710069512, -0.008098...     na            0.0   \n",
       "906  {'lattice_mat': [[4.428712142345245, 0.0938283...     na            0.0   \n",
       "219  {'lattice_mat': [[6.077481786895317, 0.0, 0.0]...     na            0.0   \n",
       "475  {'lattice_mat': [[7.542839764249747, 0.1718970...  20.29            0.0   \n",
       "696  {'lattice_mat': [[5.382597739169287, 0.0, -0.0...     na            0.0   \n",
       "\n",
       "     ... bulk_modulus_kv shear_modulus_gv mbj_bandgap hse_gap   reference  \\\n",
       "716  ...              na               na          na      na  mp-1019747   \n",
       "906  ...              na               na         0.0      na   mp-568791   \n",
       "219  ...           23.69             5.55          na      na   mp-644419   \n",
       "475  ...              na               na       2.126      na    mp-28330   \n",
       "696  ...              na               na          na      na    mp-27430   \n",
       "\n",
       "         search  pred_val       err   abs_err z_score_err  \n",
       "716  -Ca-K-O-Si -3.041397 -0.000003  0.000003   -0.227288  \n",
       "906   -Br-Ca-Si -1.159848  0.000008  0.000008   -0.227182  \n",
       "219     -H-Li-S -0.841544  0.000024  0.000024   -0.226805  \n",
       "475   -Au-Cl-Te -0.445009  0.000029  0.000029   -0.226706  \n",
       "696     -B-F-Sn -2.653481  0.000031  0.000031   -0.226656  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#select samples with minimal error\n",
    "train_subset_df = train_df.nsmallest(num_sample_in_loader, 'z_score_err')\n",
    "train_subset_df_idx = train_subset_df.index.values.tolist()\n",
    "train_subset_list = [train_data[i] for i in train_subset_df_idx]\n",
    "train_subset_dataloader = get_data_loader(train_subset_list, target, workers=4)\n",
    "train_subset_df.head() #contains the ids of train sub-selected samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load train subset to dataloader\n",
    "subset_train_x = []\n",
    "subset_train_y = []\n",
    "\n",
    "for i in train_subset_dataloader:\n",
    "    subset_train_x.append((i[0], i[1]))\n",
    "    subset_train_y.append(i[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subselect Test Samples - Most OOD (Maximum Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(test_data)\n",
    "test_df['pred_val'] = model_test_predictions\n",
    "test_df['err'] = (test_df[target] - test_df['pred_val'])\n",
    "test_df['abs_err'] = np.abs(test_df[target] - test_df['pred_val'])\n",
    "test_df['z_score_err'] = (test_df['abs_err'] - np.mean(train_df['abs_err']))/np.std(train_df['abs_err'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data range 1.56755 -2.4227\n",
      "Converting to graphs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 125.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df                                                 atoms     prop jid\n",
      "0   {'lattice_mat': [[3.790914410660539, -0.0, 0.0... -2.07159   0\n",
      "1   {'lattice_mat': [[0.0, 4.897056811995578, 4.89...  1.53929   1\n",
      "2   {'lattice_mat': [[4.110215016104089, 0.0, 0.0]... -0.04638   2\n",
      "3   {'lattice_mat': [[2.848077488322179, 2.8480774... -0.10758   3\n",
      "4   {'lattice_mat': [[4.1657904284125715, 4.165790... -0.04919   4\n",
      "5   {'lattice_mat': [[2.920865223038774, 2.9208652... -0.34463   5\n",
      "6   {'lattice_mat': [[-0.0, 5.137906744010782, 5.1...  1.00634   6\n",
      "7   {'lattice_mat': [[-0.0, 4.907221750514012, 4.9...  0.85838   7\n",
      "8   {'lattice_mat': [[3.903902177836003, 0.0, 0.0]... -1.20482   8\n",
      "9   {'lattice_mat': [[4.078736102710052, 0.3455178...  0.07844   9\n",
      "10  {'lattice_mat': [[3.0998966569685593, 0.0, 0.0... -1.88091  10\n",
      "11  {'lattice_mat': [[8.144256654569737, -0.0, 0.0... -1.34337  11\n",
      "12  {'lattice_mat': [[4.811567551604352, 0.0, 0.0]... -1.96675  12\n",
      "13  {'lattice_mat': [[-0.0, 3.24316049942265, 3.24...  0.14577  13\n",
      "14  {'lattice_mat': [[3.0379628097286413, 3.037962... -0.26977  14\n",
      "15  {'lattice_mat': [[3.760874688463202, 1.094495e... -2.42270  15\n",
      "16  {'lattice_mat': [[5.751930282761507, 0.0135341... -2.03054  16\n",
      "17  {'lattice_mat': [[5.708943922866028, 0.3141831... -2.05551  17\n",
      "18  {'lattice_mat': [[6.082481136762242, -0.039688...  0.12011  18\n",
      "19  {'lattice_mat': [[5.177548499152658, 0.1775863... -2.26851  19\n",
      "20  {'lattice_mat': [[0.0, 0.0, -3.359429146388041... -0.38932  20\n",
      "21  {'lattice_mat': [[9.508112707284857, 0.1240857... -0.30254  21\n",
      "22  {'lattice_mat': [[4.079373809661257, -9.149665... -0.11407  22\n",
      "23  {'lattice_mat': [[-1.968181375997621, 1.968181... -0.20004  23\n",
      "24  {'lattice_mat': [[4.293802725718504, 0.0, 0.0]... -1.39242  24\n",
      "25  {'lattice_mat': [[6.206290056784209, -7.174947...  0.13947  25\n",
      "26  {'lattice_mat': [[4.913303495033625, -0.021832... -1.68595  26\n",
      "27  {'lattice_mat': [[-0.0, 4.91851480463691, 4.91...  1.09065  27\n",
      "28  {'lattice_mat': [[0.0, 3.9554418923261747, 0.0... -2.39810  28\n",
      "29  {'lattice_mat': [[4.9351278097142295, 0.037722... -1.54760  29\n",
      "30  {'lattice_mat': [[2.7910974799010644, 0.0, 0.0... -1.72316  30\n",
      "31  {'lattice_mat': [[6.596915774534723, 0.0, -0.0... -0.38059  31\n",
      "32  {'lattice_mat': [[2.901284109905847, 2.9012841... -0.33344  32\n",
      "33  {'lattice_mat': [[4.86775759331703, 0.02098519... -1.58650  33\n",
      "34  {'lattice_mat': [[-0.0, 4.865908549426729, 4.8...  1.56755  34\n",
      "35  {'lattice_mat': [[3.4709209595661688, -1.12804... -0.19524  35\n",
      "36  {'lattice_mat': [[3.03948257088623, 3.03948257... -0.24587  36\n",
      "37  {'lattice_mat': [[1.964248824e-06, 2.988721859... -0.07385  37\n",
      "38  {'lattice_mat': [[5.072555347090974, 0.0195758... -1.01485  38\n",
      "39  {'lattice_mat': [[1.413929176152854, -2.448997... -2.23094  39\n",
      "40  {'lattice_mat': [[4.839493559425439, 9.7116505... -1.66274  40\n",
      "41  {'lattice_mat': [[4.8166458682114435, -0.0, 0.... -1.28488  41\n",
      "42  {'lattice_mat': [[4.927781968323723, -0.0, 0.0... -1.78124  42\n",
      "43  {'lattice_mat': [[3.0210603354185386, 3.021060... -0.23465  43\n",
      "44  {'lattice_mat': [[2.30686037078957, -2.9878659...  0.00854  44\n",
      "45  {'lattice_mat': [[5.68102309388067, -1.9677568... -0.02333  45\n",
      "46  {'lattice_mat': [[2.80754625599962, 0.0, 0.0],... -2.41430  46\n",
      "47  {'lattice_mat': [[6.84938891863269, 1.15896e-1... -0.44277  47\n",
      "48  {'lattice_mat': [[6.133066270847911, -0.153092... -0.06705  48\n",
      "49  {'lattice_mat': [[0.0, 5.343985475329381, -0.0... -1.20979  49\n",
      "building line graphs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 2272.72it/s]\n"
     ]
    }
   ],
   "source": [
    "test_subset_df = test_df.nlargest(num_sample_in_loader, 'z_score_err')\n",
    "test_subset_df_idx = test_subset_df.index.values.tolist()\n",
    "test_subset_list = [test_data[i] for i in test_subset_df_idx]\n",
    "test_subset_dataloader = get_data_loader(test_subset_list, target, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.hist(test_df['z_score_err'].values, bins=100,)\n",
    "plt.title('Test Set Predictions (Exclusively '+element_to_omit_from_training_data+')')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the Hessian Eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import botcher_hessian as hess\n",
    "from src import botcher_utilities as util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions are copy-pasted from Botcher implementation.  I put them here so that I could debug more easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def npvec_to_tensorlist(vec, params):\n",
    "    \"\"\" Convert a numpy vector to a list of tensor with the same dimensions as params\n",
    "\n",
    "        Args:\n",
    "            vec: a 1D numpy vector\n",
    "            params: a list of parameters from net\n",
    "\n",
    "        Returns:\n",
    "            rval: a list of tensors with the same shape as params\n",
    "    \"\"\"\n",
    "    loc = 0\n",
    "    rval = []\n",
    "    for p in params:\n",
    "        numel = p.data.numel()\n",
    "        rval.append(torch.from_numpy(vec[loc:loc+numel]).view(p.data.shape).float())\n",
    "        loc += numel\n",
    "    assert loc == vec.size, 'The vector has more elements than the net has parameters'\n",
    "    return rval\n",
    "\n",
    "\n",
    "def gradtensor_to_npvec(net, all_params=True):\n",
    "    \"\"\" Extract gradients from net, and return a concatenated numpy vector.\n",
    "\n",
    "        Args:\n",
    "            net: trained model\n",
    "            all_params: If all_params, then gradients w.r.t. BN parameters and bias\n",
    "            values are also included. Otherwise only gradients with dim > 1 are considered.\n",
    "\n",
    "        Returns:\n",
    "            a concatenated numpy vector containing all gradients\n",
    "    \"\"\"\n",
    "    filter = lambda p: all_params or len(p.data.size()) > 1\n",
    "    return np.concatenate([p.grad.data.cpu().numpy().ravel() for p in net.parameters() if filter(p)])\n",
    "\n",
    "\n",
    "def eval_hess_vec_prod(vec, params, net, loss_func, inputs_dataloader, outputs, use_cuda=False):\n",
    "    from torch.autograd import Variable\n",
    "    \"\"\"\n",
    "    Evaluate product of the Hessian of the loss function with a direction vector \"vec\".\n",
    "    The product result is saved in the grad of net.\n",
    "\n",
    "    Args:\n",
    "        vec: a list of tensor with the same dimensions as \"params\".\n",
    "        params: the parameter list of the net (ignoring biases and BN parameters).\n",
    "        net: model with trained parameters.\n",
    "        criterion: loss function.\n",
    "        inputs: nn inputs.\n",
    "        outputs: desired nn outputs.\n",
    "        use_cuda: use GPU.\n",
    "    \"\"\"\n",
    "\n",
    "    if use_cuda:\n",
    "        net.cuda()\n",
    "        vec = [v.cuda() for v in vec]\n",
    "\n",
    "    net.eval()\n",
    "    net.zero_grad() # clears grad for every parameter in the net\n",
    "    \n",
    "    ### OG IMPLEMENTATION\n",
    "    # pred_outputs = net(inputs.unsqueeze(-1)).flatten()\n",
    "    # pred_outputs = net(inputs_dataloader)\n",
    "    loss = torch.tensor(0.0).to(device)\n",
    "    for _, i in tqdm(enumerate(inputs_dataloader), total=len(inputs_dataloader)):\n",
    "        pred_outputs = net((i[0].to(device), i[1].to(device)))\n",
    "        # pred_outputs = np.expand_dims(pred_outputs.cpu().detach().numpy(), axis=0)[0]\n",
    "        outputs = i[2].to(device)\n",
    "        loss = torch.add(loss, loss_func(pred_outputs,outputs))\n",
    "    \n",
    "    loss = loss/len(inputs_dataloader)\n",
    "    grad_f = torch.autograd.grad(loss, inputs=params, create_graph=True, allow_unused=True)\n",
    "\n",
    "    # Compute inner product of gradient with the direction vector\n",
    "    prod = Variable(torch.zeros(1)).type(type(grad_f[0].data))\n",
    "\n",
    "    #for i in range(len(vec)):\n",
    "    tmp = []\n",
    "    for i in range(len(vec)):\n",
    "        if (grad_f[i] is not None) and (vec[i] is not None):\n",
    "            tmp.append((grad_f[i].to(device) * vec[i].to(device)).cpu().sum())\n",
    "    prod =+ sum(tmp)\n",
    "    # prod += sum([(grad_f[i] * vec[i]).cpu().sum() for i in range(len(vec))])\n",
    "\n",
    "    # Compute the Hessian-vector product, H*v\n",
    "    # prod.backward() computes dprod/dparams for every parameter in params and\n",
    "    # accumulate the gradients into the params.grad attributes\n",
    "    prod.backward()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_hessian_eigs(net, inputs, outputs, criterion, rank=0, use_cuda=False, verbose=False, all_params=True):\n",
    "    from scipy.sparse.linalg import LinearOperator, eigsh\n",
    "    import time\n",
    "    \"\"\"\n",
    "        Compute the largest and the smallest eigenvalues of the Hessian marix.\n",
    "\n",
    "        Args:\n",
    "            net: the trained model.\n",
    "            inputs: nn inputs.\n",
    "            outputs: desired nn outputs.\n",
    "            criterion: loss function.\n",
    "            rank: rank of the working node.\n",
    "            use_cuda: use GPU\n",
    "            verbose: print more information\n",
    "            all_params: use all nn parameters\n",
    "\n",
    "        Returns:\n",
    "            maxeig: max eigenvalue\n",
    "            mineig: min eigenvalue\n",
    "            hess_vec_prod.count: number of iterations for calculating max and min eigenvalues\n",
    "    \"\"\"\n",
    "    \n",
    "    if all_params:\n",
    "        params = [p for p in net.parameters()]\n",
    "    else:\n",
    "        params = [p for p in net.parameters() if len(p.size()) > 1]\n",
    "        \n",
    "    N = sum(p.numel() for p in params)\n",
    "\n",
    "    def hess_vec_prod(vec):\n",
    "        hess_vec_prod.count += 1  # simulates a static variable\n",
    "        vec = npvec_to_tensorlist(vec, params)\n",
    "        start_time = time.time()\n",
    "        eval_hess_vec_prod(vec, params, net, criterion, inputs, outputs, use_cuda)\n",
    "        prod_time = time.time() - start_time\n",
    "        if verbose and rank == 0: print(\"Iter: %d  time: %f\" % (hess_vec_prod.count, prod_time))\n",
    "        return gradtensor_to_npvec(net,all_params)\n",
    "        \n",
    "    hess_vec_prod.count = 0\n",
    "    if verbose and rank == 0: print(\"Rank %d: computing max eigenvalue\" % rank)\n",
    "\n",
    "    A = LinearOperator((N, N), matvec=hess_vec_prod)\n",
    "  \n",
    "    eigvals, eigvecs = eigsh(A, k=1, which='LM', tol=1e-2)\n",
    "    maxeig = eigvals[0]\n",
    "    maxeigvec = eigvecs\n",
    "    if verbose and rank == 0: print('max eigenvalue = %f' % maxeig)\n",
    "\n",
    "    # If the largest eigenvalue is positive, shift matrix so that any negative eigenvalue is now the largest\n",
    "    # We assume the smallest eigenvalue is zero or less, and so this shift is more than what we need\n",
    "    shift = maxeig*1.0\n",
    "    def shifted_hess_vec_prod(vec):\n",
    "        return hess_vec_prod(vec) - shift*vec\n",
    "\n",
    "    if verbose and rank == 0: print(\"Rank %d: Computing shifted eigenvalue\" % rank)\n",
    "\n",
    "    A = LinearOperator((N, N), matvec=shifted_hess_vec_prod)\n",
    "    eigvals, eigvecs = eigsh(A, k=1, which='LM', tol=1e-2)\n",
    "    eigvals = eigvals + shift\n",
    "    mineig = eigvals[0]\n",
    "    mineigvec = eigvecs\n",
    "    if verbose and rank == 0: print('min eigenvalue = ' + str(mineig))\n",
    "\n",
    "    if maxeig <= 0 and mineig > 0:\n",
    "        maxeig, mineig = mineig, maxeig\n",
    "        maxeig, mineig = mineigvec, maxeigvec\n",
    "\n",
    "    return maxeig, mineig, maxeigvec, mineigvec, hess_vec_prod.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defaults from OG implementation\n",
    "loss_func = torch.nn.MSELoss()\n",
    "func = copy.deepcopy(model)\n",
    "og_params = [i[1] for i in func.named_parameters() if len(i[1].size()) > 1]\n",
    "og_layer_names = [i[0] for i in func.named_parameters() if len(i[1].size())>1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next cell calculates the eigenvectors, and can take considerable time (upwards of 40 minutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here, we are computing the hessian eigenvectors using 3(or more) samples that 1. do not contain Fe, 2. is well predicted by the model (defined by existing model weights)\n",
    "\n",
    "then, we perturb the model such that the rate of loss increase would increase or we perturb the model such that the rate of loss increase would be constant\n",
    "\n",
    "we then test these perturbed model's performance on the same 3 samples that it had been predicting well to construct the loss land scape.\n",
    "\n",
    "- on the other hand, we will be picking samples that do not contain Fe and was not well predicted by the original model. they will not be involved in the hessian computation, so the perturbation has nothing to do with them. we will then test the perturbed model's performance on these samples\n",
    "\n",
    "hypothesis (need to be validated):\n",
    "\n",
    "perturbing in the direction of max eigenvector should increase/decress the loss by a lot (but that would be true for first derivative??? ask)\n",
    "\n",
    "perturbing in the direction of min eigenvector should not increase/decress the loss by a lot since it is the flattest direction\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- also, the choice of loss function is involved twice, 1. when we are choosing the samples; 2. when we are computing the hessian; 3. when we are visualizing the loss landscape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]c:\\Users\\EthanH24\\anaconda3\\envs\\losslandscapefeb8gpu4\\lib\\site-packages\\torch\\nn\\modules\\loss.py:538: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "100%|██████████| 50/50 [00:02<00:00, 20.27it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 23.41it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 20.84it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 19.82it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 21.51it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 23.56it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 20.79it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 23.80it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 24.02it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 23.57it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 23.04it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 23.41it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 24.40it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 20.16it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 19.51it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 22.84it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 23.36it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 23.65it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 23.69it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 24.06it/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 12.41it/s]\n",
      "100%|██████████| 50/50 [00:03<00:00, 13.58it/s]\n",
      "100%|██████████| 50/50 [00:03<00:00, 13.38it/s]\n",
      "100%|██████████| 50/50 [00:03<00:00, 13.17it/s]\n",
      "100%|██████████| 50/50 [00:03<00:00, 14.16it/s]\n",
      "100%|██████████| 50/50 [00:03<00:00, 13.83it/s]\n",
      "100%|██████████| 50/50 [00:03<00:00, 14.22it/s]\n",
      "100%|██████████| 50/50 [00:03<00:00, 14.06it/s]\n",
      "100%|██████████| 50/50 [00:03<00:00, 13.35it/s]\n",
      "100%|██████████| 50/50 [00:03<00:00, 14.28it/s]\n",
      "100%|██████████| 50/50 [00:03<00:00, 13.08it/s]\n",
      "100%|██████████| 50/50 [00:03<00:00, 15.07it/s]\n",
      "100%|██████████| 50/50 [00:03<00:00, 13.54it/s]\n",
      "100%|██████████| 50/50 [00:03<00:00, 14.05it/s]\n",
      "100%|██████████| 50/50 [00:03<00:00, 13.14it/s]\n",
      "100%|██████████| 50/50 [00:03<00:00, 14.42it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 23.55it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 20.91it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 19.43it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 23.55it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 22.74it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 23.11it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 22.45it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 23.53it/s]\n"
     ]
    }
   ],
   "source": [
    "maxeig, mineig, maxeigvec, mineigvec, num_iter = min_max_hessian_eigs(\n",
    "    func, train_subset_dataloader, subset_train_y, loss_func, all_params=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we found two directions of steepest and flattest curvature, the eigenvectors have unit length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48.10708 -9.479919071964105e-10\n"
     ]
    }
   ],
   "source": [
    "print(maxeig, mineig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Euclidean norm of the eigenvector is: 1.0000001192092896\n"
     ]
    }
   ],
   "source": [
    "norm = np.linalg.norm(maxeigvec)\n",
    "print(f\"The Euclidean norm of the eigenvector is: {norm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Euclidean norm of the weights is: 520.29345703125\n"
     ]
    }
   ],
   "source": [
    "def unpack_tensors_to_1d(tensor_list):\n",
    "    \"\"\"Unpack a list of 2D tensors into a 1D NumPy array.\n",
    "\n",
    "    Args:\n",
    "        tensor_list: A list of 2D PyTorch tensors.\n",
    "\n",
    "    Returns:\n",
    "        A 1D NumPy array containing all elements from the tensors.\n",
    "    \"\"\"\n",
    "    # Flatten each tensor, detach from the computation graph, move to CPU, and convert to a NumPy array\n",
    "    flattened_arrays = [tensor.detach().cpu().flatten().numpy() for tensor in tensor_list]\n",
    "    \n",
    "    # Concatenate all flattened arrays into a single 1D array\n",
    "    result = np.concatenate(flattened_arrays)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Now you can call the function without encountering the TypeError\n",
    "unpacked_array = unpack_tensors_to_1d(og_params)\n",
    "norm = np.linalg.norm(unpacked_array)\n",
    "print(f\"The Euclidean norm of the weights is: {norm}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatting as Two New Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create two models with weights being the two most dominant hessian eigenvector and save to local path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_model_wts = hess.npvec_to_tensorlist(maxeigvec, og_params)\n",
    "min_model_wts = hess.npvec_to_tensorlist(mineigvec, og_params)\n",
    "\n",
    "model_eig_max = copy.deepcopy(func)\n",
    "model_eig_min = copy.deepcopy(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_IncompatibleKeys(missing_keys=['atom_embedding.layer.1.running_mean', 'atom_embedding.layer.1.running_var', 'edge_embedding.0.centers', 'edge_embedding.1.layer.1.running_mean', 'edge_embedding.1.layer.1.running_var', 'edge_embedding.2.layer.1.running_mean', 'edge_embedding.2.layer.1.running_var', 'angle_embedding.0.centers', 'angle_embedding.1.layer.1.running_mean', 'angle_embedding.1.layer.1.running_var', 'angle_embedding.2.layer.1.running_mean', 'angle_embedding.2.layer.1.running_var', 'alignn_layers.0.node_update.bn_edges.running_mean', 'alignn_layers.0.node_update.bn_edges.running_var', 'alignn_layers.0.node_update.bn_nodes.running_mean', 'alignn_layers.0.node_update.bn_nodes.running_var', 'alignn_layers.0.edge_update.bn_edges.running_mean', 'alignn_layers.0.edge_update.bn_edges.running_var', 'alignn_layers.0.edge_update.bn_nodes.running_mean', 'alignn_layers.0.edge_update.bn_nodes.running_var', 'alignn_layers.1.node_update.bn_edges.running_mean', 'alignn_layers.1.node_update.bn_edges.running_var', 'alignn_layers.1.node_update.bn_nodes.running_mean', 'alignn_layers.1.node_update.bn_nodes.running_var', 'alignn_layers.1.edge_update.bn_edges.running_mean', 'alignn_layers.1.edge_update.bn_edges.running_var', 'alignn_layers.1.edge_update.bn_nodes.running_mean', 'alignn_layers.1.edge_update.bn_nodes.running_var', 'alignn_layers.2.node_update.bn_edges.running_mean', 'alignn_layers.2.node_update.bn_edges.running_var', 'alignn_layers.2.node_update.bn_nodes.running_mean', 'alignn_layers.2.node_update.bn_nodes.running_var', 'alignn_layers.2.edge_update.bn_edges.running_mean', 'alignn_layers.2.edge_update.bn_edges.running_var', 'alignn_layers.2.edge_update.bn_nodes.running_mean', 'alignn_layers.2.edge_update.bn_nodes.running_var', 'alignn_layers.3.node_update.bn_edges.running_mean', 'alignn_layers.3.node_update.bn_edges.running_var', 'alignn_layers.3.node_update.bn_nodes.running_mean', 'alignn_layers.3.node_update.bn_nodes.running_var', 'alignn_layers.3.edge_update.bn_edges.running_mean', 'alignn_layers.3.edge_update.bn_edges.running_var', 'alignn_layers.3.edge_update.bn_nodes.running_mean', 'alignn_layers.3.edge_update.bn_nodes.running_var', 'gcn_layers.0.bn_edges.running_mean', 'gcn_layers.0.bn_edges.running_var', 'gcn_layers.0.bn_nodes.running_mean', 'gcn_layers.0.bn_nodes.running_var', 'gcn_layers.1.bn_edges.running_mean', 'gcn_layers.1.bn_edges.running_var', 'gcn_layers.1.bn_nodes.running_mean', 'gcn_layers.1.bn_nodes.running_var', 'gcn_layers.2.bn_edges.running_mean', 'gcn_layers.2.bn_edges.running_var', 'gcn_layers.2.bn_nodes.running_mean', 'gcn_layers.2.bn_nodes.running_var', 'gcn_layers.3.bn_edges.running_mean', 'gcn_layers.3.bn_edges.running_var', 'gcn_layers.3.bn_nodes.running_mean', 'gcn_layers.3.bn_nodes.running_var'], unexpected_keys=[])\n",
      "_IncompatibleKeys(missing_keys=['atom_embedding.layer.1.running_mean', 'atom_embedding.layer.1.running_var', 'edge_embedding.0.centers', 'edge_embedding.1.layer.1.running_mean', 'edge_embedding.1.layer.1.running_var', 'edge_embedding.2.layer.1.running_mean', 'edge_embedding.2.layer.1.running_var', 'angle_embedding.0.centers', 'angle_embedding.1.layer.1.running_mean', 'angle_embedding.1.layer.1.running_var', 'angle_embedding.2.layer.1.running_mean', 'angle_embedding.2.layer.1.running_var', 'alignn_layers.0.node_update.bn_edges.running_mean', 'alignn_layers.0.node_update.bn_edges.running_var', 'alignn_layers.0.node_update.bn_nodes.running_mean', 'alignn_layers.0.node_update.bn_nodes.running_var', 'alignn_layers.0.edge_update.bn_edges.running_mean', 'alignn_layers.0.edge_update.bn_edges.running_var', 'alignn_layers.0.edge_update.bn_nodes.running_mean', 'alignn_layers.0.edge_update.bn_nodes.running_var', 'alignn_layers.1.node_update.bn_edges.running_mean', 'alignn_layers.1.node_update.bn_edges.running_var', 'alignn_layers.1.node_update.bn_nodes.running_mean', 'alignn_layers.1.node_update.bn_nodes.running_var', 'alignn_layers.1.edge_update.bn_edges.running_mean', 'alignn_layers.1.edge_update.bn_edges.running_var', 'alignn_layers.1.edge_update.bn_nodes.running_mean', 'alignn_layers.1.edge_update.bn_nodes.running_var', 'alignn_layers.2.node_update.bn_edges.running_mean', 'alignn_layers.2.node_update.bn_edges.running_var', 'alignn_layers.2.node_update.bn_nodes.running_mean', 'alignn_layers.2.node_update.bn_nodes.running_var', 'alignn_layers.2.edge_update.bn_edges.running_mean', 'alignn_layers.2.edge_update.bn_edges.running_var', 'alignn_layers.2.edge_update.bn_nodes.running_mean', 'alignn_layers.2.edge_update.bn_nodes.running_var', 'alignn_layers.3.node_update.bn_edges.running_mean', 'alignn_layers.3.node_update.bn_edges.running_var', 'alignn_layers.3.node_update.bn_nodes.running_mean', 'alignn_layers.3.node_update.bn_nodes.running_var', 'alignn_layers.3.edge_update.bn_edges.running_mean', 'alignn_layers.3.edge_update.bn_edges.running_var', 'alignn_layers.3.edge_update.bn_nodes.running_mean', 'alignn_layers.3.edge_update.bn_nodes.running_var', 'gcn_layers.0.bn_edges.running_mean', 'gcn_layers.0.bn_edges.running_var', 'gcn_layers.0.bn_nodes.running_mean', 'gcn_layers.0.bn_nodes.running_var', 'gcn_layers.1.bn_edges.running_mean', 'gcn_layers.1.bn_edges.running_var', 'gcn_layers.1.bn_nodes.running_mean', 'gcn_layers.1.bn_nodes.running_var', 'gcn_layers.2.bn_edges.running_mean', 'gcn_layers.2.bn_edges.running_var', 'gcn_layers.2.bn_nodes.running_mean', 'gcn_layers.2.bn_nodes.running_var', 'gcn_layers.3.bn_edges.running_mean', 'gcn_layers.3.bn_edges.running_var', 'gcn_layers.3.bn_nodes.running_mean', 'gcn_layers.3.bn_nodes.running_var'], unexpected_keys=[])\n"
     ]
    }
   ],
   "source": [
    "# There will be some incompatible keys due to the batch norm values\n",
    "# the original batch norm values will be retained\n",
    "model_eig_max = force_wts_into_model(og_layer_names, max_model_wts, model_eig_max,  model_wt_dict)\n",
    "model_eig_min = force_wts_into_model(og_layer_names, min_model_wts, model_eig_min,  model_wt_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_eig_max.state_dict(), 'model_eig_max.pt')\n",
    "torch.save(model_eig_min.state_dict(), 'model_eig_min.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inspecting the original weights and hessian eigenvector model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0489, -0.0350,  0.1071, -0.1211], device='cuda:0',\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "og_params[0][0][:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.3937840e-05, 5.1789698e-06, 1.6494187e-04, 0.0000000e+00],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxeigvec[:4].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.3938e-05, 5.1790e-06, 1.6494e-04, 0.0000e+00])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_model_wts[0][0][:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 1.3938e-05,  5.1790e-06,  1.6494e-04,  ...,  3.7632e-05,\n",
       "          1.5899e-05,  0.0000e+00],\n",
       "        [ 1.1868e-05,  7.6569e-06, -2.0781e-05,  ..., -1.9890e-05,\n",
       "         -8.2938e-07,  0.0000e+00],\n",
       "        [ 1.3115e-06, -4.7240e-06, -1.3706e-05,  ..., -1.2141e-05,\n",
       "          2.5079e-06,  0.0000e+00],\n",
       "        ...,\n",
       "        [ 3.1603e-05,  5.8877e-06,  5.8690e-06,  ..., -2.1886e-05,\n",
       "          1.2498e-06,  0.0000e+00],\n",
       "        [ 6.6453e-06,  2.4982e-05,  7.2249e-05,  ...,  5.0897e-05,\n",
       "          2.1233e-05,  0.0000e+00],\n",
       "        [ 4.5978e-06,  5.8054e-05, -2.7311e-05,  ..., -4.1944e-06,\n",
       "          4.1606e-05,  0.0000e+00]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_model_params = [i[1] for i in model_eig_max.named_parameters() if len(i[1].size()) > 1]\n",
    "max_model_params[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "losslandscapefeb8gpu4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
